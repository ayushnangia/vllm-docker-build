# Dockerfile for SGLang parent commit da19434c2f3cbe4f367f84993da0bcbd84efb6ba
# This uses the "Proper" Triton Server base image found in the repo at this time.
# Architecture: linux/amd64 (GPU)

FROM nvcr.io/nvidia/tritonserver:24.01-py3

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

ARG SGLANG_COMMIT=da19434c2f3cbe4f367f84993da0bcbd84efb6ba

WORKDIR /sgl-workspace

# Copy ONLY the source for this specific commit
COPY . /sgl-workspace/sglang

# Build flashinfer from source (old versions not on PyPI for Python 3.10)
RUN pip install --upgrade pip && \
    pip install ninja numpy && \
    pip install torch==2.2.1 --extra-index-url https://download.pytorch.org/whl/cu121 && \
    git clone --recursive https://github.com/flashinfer-ai/flashinfer.git /tmp/flashinfer && \
    cd /tmp/flashinfer && git checkout v0.1.2 && \
    cd python && TORCH_CUDA_ARCH_LIST="8.0;8.6;8.9;9.0" MAX_JOBS=64 pip install --no-build-isolation . && \
    rm -rf /tmp/flashinfer

# Patch pyproject.toml to skip flashinfer install (already built)
RUN sed -i 's/"flashinfer[^"]*",*//g' /sgl-workspace/sglang/python/pyproject.toml

# Install SGLang package and datasets (matching the repo's Triton Dockerfile)
WORKDIR /sgl-workspace/sglang
RUN pip install -e "python[all]" && \
    pip install datasets

# Write commit hash for verification
RUN mkdir -p /opt && echo "$SGLANG_COMMIT" > /opt/sglang_commit.txt

WORKDIR /sgl-workspace
CMD ["python3", "-c", "import sglang; print('SGLang Triton-based parent loaded successfully')"]
