{"commit_hash": "021f76e4f49861b2e9ea9ccff06a46d577e3c548", "commit_short": "021f76e4f498", "commit_subject": "[Perf] Refactor LoRAManager to eliminate stream syncs and redundant computations  (#6994)", "pr_url": "https://github.com/sgl-project/sglang/pull/6994", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python3 -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompt 480 --request-rate 8 --lora-name lora", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Docker: Modal image build failed - rebuild Docker image", "error_date": "2026-01-04", "parent_commit": "777688b8929c877e4e28c2eac208d776abe4c3af", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.12-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator --break-system-packages\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six --break-system-packages --ignore-installed \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118 --break-system-packages; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && if [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu126 --break-system-packages; \\\n       else \\\n         python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} --break-system-packages; \\\n       fi \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --break-system-packages \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps --break-system-packages; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.12-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator --break-system-packages\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six --break-system-packages --ignore-installed \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118 --break-system-packages; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && if [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu126 --break-system-packages; \\\n       else \\\n         python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} --break-system-packages; \\\n       fi \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --break-system-packages \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps --break-system-packages; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "09deb20deef8181a23f66c933ea74b86fee47366", "commit_short": "09deb20deef8", "commit_subject": "Optimize the memory usage of logits processor (#420)", "pr_url": "https://github.com/sgl-project/sglang/pull/420", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "33b242df303e03886835d08a583fefe979a3ee88", "human_throughput": 1598.7, "has_dockerfile": false, "dockerfile_path": null, "dockerfile_content": null, "parent_has_dockerfile": false, "parent_dockerfile_path": null, "parent_dockerfile_content": null}
{"commit_hash": "132dad874d2e44592d03a112e4b7d63b153e8346", "commit_short": "132dad874d2e", "commit_subject": "[PD] Optimize transfer queue forward logic for dummy rank (#6922)", "pr_url": "https://github.com/sgl-project/sglang/pull/6922", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": false, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "error": "Baseline phase produced empty metrics", "error_date": "2026-01-04", "parent_commit": "60fdad7cf343333e956a3889c12956396a1516bf", "human_throughput": 1551.9, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "187b85b7f38496653948a2aba546d53c09ada0f3", "commit_short": "187b85b7f384", "commit_subject": "[PD] Optimize custom mem pool usage and bump mooncake version (#7393)", "pr_url": "https://github.com/sgl-project/sglang/pull/7393", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": false, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "error": "Baseline phase produced empty metrics", "error_date": "2026-01-04", "parent_commit": "ceba0ce4f661722198f6568a54ba20cf06b7e033", "human_throughput": 1529.8, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.6.1\nFROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive \\\n    CUDA_HOME=/usr/local/cuda \\\n    GDRCOPY_HOME=/usr/src/gdrdrv-2.4.4/ \\\n    NVSHMEM_DIR=/sgl-workspace/nvshmem/install\n\n# Set timezone and install all packages\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n && apt-get update && apt-get install -y --no-install-recommends \\\n    tzdata \\\n    software-properties-common netcat-openbsd kmod unzip openssh-server \\\n    curl wget lsof zsh ccache tmux htop git-lfs tree \\\n    python3 python3-pip python3-dev libpython3-dev \\\n    build-essential cmake \\\n    libopenmpi-dev libnuma1 libnuma-dev \\\n    libibverbs-dev libibverbs1 libibumad3 \\\n    librdmacm1 libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnl-3-dev \\\n    ibverbs-providers infiniband-diags perftest \\\n    libgoogle-glog-dev libgtest-dev libjsoncpp-dev libunwind-dev \\\n    libboost-all-dev libssl-dev \\\n    libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc \\\n    pybind11-dev \\\n    libhiredis-dev libcurl4-openssl-dev \\\n    libczmq4 libczmq-dev \\\n    libfabric-dev \\\n    patchelf \\\n    nvidia-dkms-550 \\\n    devscripts debhelper fakeroot dkms check libsubunit0 libsubunit-dev \\\n && ln -sf /usr/bin/python3 /usr/bin/python \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# GDRCopy installation\nRUN mkdir -p /tmp/gdrcopy && cd /tmp \\\n && git clone https://github.com/NVIDIA/gdrcopy.git -b v2.4.4 \\\n && cd gdrcopy/packages \\\n && CUDA=/usr/local/cuda ./build-deb-packages.sh \\\n && dpkg -i gdrdrv-dkms_*.deb libgdrapi_*.deb gdrcopy-tests_*.deb gdrcopy_*.deb \\\n && cd / && rm -rf /tmp/gdrcopy\n\n# Fix DeepEP IBGDA symlink\nRUN ln -sf /usr/lib/x86_64-linux-gnu/libmlx5.so.1 /usr/lib/x86_64-linux-gnu/libmlx5.so\n\n# Clone and install SGLang\nWORKDIR /sgl-workspace\nRUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel html5lib six \\\n && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n && cd sglang \\\n && case \"$CUDA_VERSION\" in \\\n      12.6.1) CUINDEX=126 ;; \\\n      12.8.1) CUINDEX=128 ;; \\\n      *) echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1 ;; \\\n    esac \\\n && python3 -m pip install --no-cache-dir -e \"python[${BUILD_TYPE}]\" --extra-index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n      python3 -m pip install --no-cache-dir nvidia-nccl-cu12==2.27.3 --force-reinstall --no-deps ; \\\n      python3 -m pip install --no-cache-dir https://github.com/sgl-project/whl/releases/download/v0.1.9/sgl_kernel-0.1.9+cu128-cp39-abi3-manylinux2014_x86_64.whl --force-reinstall --no-deps ; \\\n    fi\n\n# Build and install NVSHMEM + DeepEP\nRUN wget https://developer.download.nvidia.com/compute/redist/nvshmem/3.2.5/source/nvshmem_src_3.2.5-1.txz \\\n && git clone https://github.com/deepseek-ai/DeepEP.git \\\n && tar -xf nvshmem_src_3.2.5-1.txz && mv nvshmem_src nvshmem \\\n && cd nvshmem \\\n && git apply /sgl-workspace/DeepEP/third-party/nvshmem.patch \\\n && sed -i '1i#include <unistd.h>' examples/moe_shuffle.cu \\\n && rm -f /sgl-workspace/nvshmem_src_3.2.5-1.txz \\\n && NVSHMEM_SHMEM_SUPPORT=0 \\\n    NVSHMEM_UCX_SUPPORT=0 \\\n    NVSHMEM_USE_NCCL=0 \\\n    NVSHMEM_MPI_SUPPORT=0 \\\n    NVSHMEM_IBGDA_SUPPORT=1 \\\n    NVSHMEM_PMIX_SUPPORT=0 \\\n    NVSHMEM_TIMEOUT_DEVICE_POLLING=0 \\\n    NVSHMEM_USE_GDRCOPY=1 \\\n    cmake -S . -B build/ -DCMAKE_INSTALL_PREFIX=${NVSHMEM_DIR} -DCMAKE_CUDA_ARCHITECTURES=90 \\\n && cmake --build build --target install -j \\\n && cd /sgl-workspace/DeepEP \\\n && NVSHMEM_DIR=${NVSHMEM_DIR} pip install .\n\n# Python tools\nRUN python3 -m pip install --no-cache-dir \\\n    datamodel_code_generator \\\n    mooncake_transfer_engine==0.3.3.post2 \\\n    pre-commit \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    uv \\\n    wheel \\\n    scikit-build-core\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.6.1\nFROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive \\\n    CUDA_HOME=/usr/local/cuda \\\n    GDRCOPY_HOME=/usr/src/gdrdrv-2.4.4/ \\\n    NVSHMEM_DIR=/sgl-workspace/nvshmem/install\n\n# Set timezone and install all packages\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n && apt-get update && apt-get install -y --no-install-recommends \\\n    tzdata \\\n    software-properties-common netcat-openbsd kmod unzip openssh-server \\\n    curl wget lsof zsh ccache tmux htop git-lfs tree \\\n    python3 python3-pip python3-dev libpython3-dev \\\n    build-essential cmake \\\n    libopenmpi-dev libnuma1 libnuma-dev \\\n    libibverbs-dev libibverbs1 libibumad3 \\\n    librdmacm1 libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnl-3-dev \\\n    ibverbs-providers infiniband-diags perftest \\\n    libgoogle-glog-dev libgtest-dev libjsoncpp-dev libunwind-dev \\\n    libboost-all-dev libssl-dev \\\n    libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc \\\n    pybind11-dev \\\n    libhiredis-dev libcurl4-openssl-dev \\\n    libczmq4 libczmq-dev \\\n    libfabric-dev \\\n    patchelf \\\n    nvidia-dkms-550 \\\n    devscripts debhelper fakeroot dkms check libsubunit0 libsubunit-dev \\\n && ln -sf /usr/bin/python3 /usr/bin/python \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# GDRCopy installation\nRUN mkdir -p /tmp/gdrcopy && cd /tmp \\\n && git clone https://github.com/NVIDIA/gdrcopy.git -b v2.4.4 \\\n && cd gdrcopy/packages \\\n && CUDA=/usr/local/cuda ./build-deb-packages.sh \\\n && dpkg -i gdrdrv-dkms_*.deb libgdrapi_*.deb gdrcopy-tests_*.deb gdrcopy_*.deb \\\n && cd / && rm -rf /tmp/gdrcopy\n\n# Fix DeepEP IBGDA symlink\nRUN ln -sf /usr/lib/x86_64-linux-gnu/libmlx5.so.1 /usr/lib/x86_64-linux-gnu/libmlx5.so\n\n# Clone and install SGLang\nWORKDIR /sgl-workspace\nRUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel html5lib six \\\n && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n && cd sglang \\\n && case \"$CUDA_VERSION\" in \\\n      12.6.1) CUINDEX=126 ;; \\\n      12.8.1) CUINDEX=128 ;; \\\n      *) echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1 ;; \\\n    esac \\\n && python3 -m pip install --no-cache-dir -e \"python[${BUILD_TYPE}]\" --extra-index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n      python3 -m pip install --no-cache-dir nvidia-nccl-cu12==2.27.3 --force-reinstall --no-deps ; \\\n      python3 -m pip install --no-cache-dir https://github.com/sgl-project/whl/releases/download/v0.1.9/sgl_kernel-0.1.9+cu128-cp39-abi3-manylinux2014_x86_64.whl --force-reinstall --no-deps ; \\\n    fi\n\n# Build and install NVSHMEM + DeepEP\nRUN wget https://developer.download.nvidia.com/compute/redist/nvshmem/3.2.5/source/nvshmem_src_3.2.5-1.txz \\\n && git clone https://github.com/deepseek-ai/DeepEP.git \\\n && tar -xf nvshmem_src_3.2.5-1.txz && mv nvshmem_src nvshmem \\\n && cd nvshmem \\\n && git apply /sgl-workspace/DeepEP/third-party/nvshmem.patch \\\n && sed -i '1i#include <unistd.h>' examples/moe_shuffle.cu \\\n && rm -f /sgl-workspace/nvshmem_src_3.2.5-1.txz \\\n && NVSHMEM_SHMEM_SUPPORT=0 \\\n    NVSHMEM_UCX_SUPPORT=0 \\\n    NVSHMEM_USE_NCCL=0 \\\n    NVSHMEM_MPI_SUPPORT=0 \\\n    NVSHMEM_IBGDA_SUPPORT=1 \\\n    NVSHMEM_PMIX_SUPPORT=0 \\\n    NVSHMEM_TIMEOUT_DEVICE_POLLING=0 \\\n    NVSHMEM_USE_GDRCOPY=1 \\\n    cmake -S . -B build/ -DCMAKE_INSTALL_PREFIX=${NVSHMEM_DIR} -DCMAKE_CUDA_ARCHITECTURES=90 \\\n && cmake --build build --target install -j \\\n && cd /sgl-workspace/DeepEP \\\n && NVSHMEM_DIR=${NVSHMEM_DIR} pip install .\n\n# Python tools\nRUN python3 -m pip install --no-cache-dir \\\n    datamodel_code_generator \\\n    mooncake_transfer_engine==0.3.3.post2 \\\n    pre-commit \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    uv \\\n    wheel \\\n    scikit-build-core\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "1acca3a2c685221cdb181c2abda4f635e1ead435", "commit_short": "1acca3a2c685", "commit_subject": "FA3 speed up: skip len operation and get batch size directly from forward batch (#5969)", "pr_url": "https://github.com/sgl-project/sglang/pull/5969", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Server failed to start", "error_date": "2026-01-06", "parent_commit": "6ea1e6ac6e2fa949cebd1b4338f9bfb7036d14fe", "human_only_success": false, "human_only_date": "2026-01-06", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "1bf1cf195302fdff14a4321eb8a17831f5c2fc11", "commit_short": "1bf1cf195302", "commit_subject": "Reduce overhead when `fork(1)` (#375)", "pr_url": "https://github.com/sgl-project/sglang/pull/375", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "error": "Benchmark failed", "error_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "e822e5900b98d89d19e0a293d9ad384f4df2945a", "human_throughput": 1591.9, "has_dockerfile": false, "dockerfile_path": null, "dockerfile_content": null, "parent_has_dockerfile": false, "parent_dockerfile_path": null, "parent_dockerfile_content": null}
{"commit_hash": "2854a5ea9fbb31165936f633ab99915dec760f8d", "commit_short": "2854a5ea9fbb", "commit_subject": "Fix the overhead due to penalizer in bench_latency (#1496)", "pr_url": "https://github.com/sgl-project/sglang/pull/1496", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Docker: flashinfer/torch ABI mismatch - rebuild image with matching versions", "error_date": "2026-01-04", "parent_commit": "42a2d82ba71dc86ca3b6342c978db450658b750c", "human_only_success": true, "human_only_date": "2026-01-06", "human_throughput": 1446.3, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "2a754e57b052e249ed4f8572cb6f0069ba6a495e", "commit_short": "2a754e57b052", "commit_subject": "2x performance improvement for large prefill & Fix workspace conflicts (#579)", "pr_url": "https://github.com/sgl-project/sglang/pull/579", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": false, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "error": "Baseline phase produced empty metrics", "error_date": "2026-01-04", "parent_commit": "96c503eb6029d37f896e91466e23469378dfc3dc", "human_throughput": 1598.5, "has_dockerfile": false, "dockerfile_path": null, "dockerfile_content": null, "parent_has_dockerfile": false, "parent_dockerfile_path": null, "parent_dockerfile_content": null}
{"commit_hash": "2bd18e2d767e3a0f8afb5aff427bc8e6e4d297c0", "commit_short": "2bd18e2d767e", "commit_subject": "Memory pool: Minor optimize to avoid to (#2901)", "pr_url": "https://github.com/sgl-project/sglang/pull/2901", "models": ["meta-llama/Llama-2-7b-hf"], "perf_command": "python3 -m sglang.bench_one_batch_server --model-path meta-llama/Llama-2-7b-hf --mem-fraction-static 0.8 --batch-size 48 --disable-overlap-schedule", "hardware": "H100", "has_serving": false, "repo": "sglang", "error": "Model load failure (no metrics)", "error_date": "2026-01-06", "parent_commit": "83452dbb4a19c6a2461e972eb2b64a2df9a466b8", "human_only_success": false, "human_only_date": "2026-01-06", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu121/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu124/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu118/torch2.4/flashinfer/; \\\n         else \\\n           echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n         fi; \\\n       else \\\n         if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu121/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu124/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu118/torch2.4/flashinfer/; \\\n         else \\\n           echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n         fi; \\\n       fi\n\nRUN python3 -m pip cache purge\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu121/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu124/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu118/torch2.4/flashinfer/; \\\n         else \\\n           echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n         fi; \\\n       else \\\n         if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu121/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu124/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu118/torch2.4/flashinfer/; \\\n         else \\\n           echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n         fi; \\\n       fi\n\nRUN python3 -m pip cache purge\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "3212c2ad3f7e4fb473dc807b4b176020a778ed5b", "commit_short": "3212c2ad3f7e", "commit_subject": "vlm: optimize tensor transport (#6003)", "pr_url": "https://github.com/sgl-project/sglang/pull/6003", "models": ["OpenGVLab/InternVL2_5-8B"], "perf_command": "python3 -m sglang.bench_serving --backend sglang --model OpenGVLab/InternVL2_5-8B", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Server failed to start", "error_date": "2026-01-06", "parent_commit": "534756749ae4e664f762de2645a4f63ca2901bab", "human_only_success": false, "human_only_date": "2026-01-06", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.6.1\nFROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04\n\nARG BUILD_TYPE=all\nARG DEEPEP_COMMIT=b6ce310bb0b75079682d09bc2ebc063a074fbd58\nARG CMAKE_BUILD_PARALLEL_LEVEL=2\nENV DEBIAN_FRONTEND=noninteractive \\\n    CUDA_HOME=/usr/local/cuda \\\n    GDRCOPY_HOME=/usr/src/gdrdrv-2.4.4/ \\\n    NVSHMEM_DIR=/sgl-workspace/nvshmem/install\n\n# Set timezone and install all packages\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n && apt-get update && apt-get install -y --no-install-recommends \\\n    tzdata \\\n    software-properties-common netcat-openbsd kmod unzip openssh-server \\\n    curl wget lsof zsh ccache tmux htop git-lfs tree \\\n    python3 python3-pip python3-dev libpython3-dev python3-venv \\\n    build-essential cmake \\\n    libopenmpi-dev libnuma1 libnuma-dev \\\n    libibverbs-dev libibverbs1 libibumad3 \\\n    librdmacm1 libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnl-3-dev \\\n    ibverbs-providers infiniband-diags perftest \\\n    libgoogle-glog-dev libgtest-dev libjsoncpp-dev libunwind-dev \\\n    libboost-all-dev libssl-dev \\\n    libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc \\\n    pybind11-dev \\\n    libhiredis-dev libcurl4-openssl-dev \\\n    libczmq4 libczmq-dev \\\n    libfabric-dev \\\n    patchelf \\\n    nvidia-dkms-550 \\\n    devscripts debhelper fakeroot dkms check libsubunit0 libsubunit-dev \\\n && ln -sf /usr/bin/python3 /usr/bin/python \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# GDRCopy installation\nRUN mkdir -p /tmp/gdrcopy && cd /tmp \\\n && git clone https://github.com/NVIDIA/gdrcopy.git -b v2.4.4 \\\n && cd gdrcopy/packages \\\n && CUDA=/usr/local/cuda ./build-deb-packages.sh \\\n && dpkg -i gdrdrv-dkms_*.deb libgdrapi_*.deb gdrcopy-tests_*.deb gdrcopy_*.deb \\\n && cd / && rm -rf /tmp/gdrcopy\n\n# Fix DeepEP IBGDA symlink\nRUN ln -sf /usr/lib/x86_64-linux-gnu/libmlx5.so.1 /usr/lib/x86_64-linux-gnu/libmlx5.so\n\n# Clone and install SGLang\nWORKDIR /sgl-workspace\nRUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel html5lib six \\\n && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n && cd sglang \\\n && case \"$CUDA_VERSION\" in \\\n      12.6.1) CUINDEX=126 ;; \\\n      12.8.1) CUINDEX=128 ;; \\\n      *) echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1 ;; \\\n    esac \\\n && python3 -m pip install --no-cache-dir -e \"python[${BUILD_TYPE}]\" --extra-index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n && python3 -m pip install --no-cache-dir nvidia-nccl-cu12==2.27.6 --force-reinstall --no-deps \\\n && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n      python3 -m pip install --no-cache-dir https://github.com/sgl-project/whl/releases/download/v0.2.7/sgl_kernel-0.2.7+cu128-cp39-abi3-manylinux2014_x86_64.whl --force-reinstall --no-deps ; \\\n    fi\n\n# Build and install NVSHMEM + DeepEP\nRUN wget https://developer.download.nvidia.com/compute/redist/nvshmem/3.3.9/source/nvshmem_src_cuda12-all-all-3.3.9.tar.gz \\\n && git clone https://github.com/deepseek-ai/DeepEP.git \\\n && cd DeepEP && git checkout ${DEEPEP_COMMIT} && cd .. \\\n && tar -xf nvshmem_src_cuda12-all-all-3.3.9.tar.gz && mv nvshmem_src nvshmem \\\n && cd nvshmem \\\n && rm -f /sgl-workspace/nvshmem_src_cuda12-all-all-3.3.9.tar.gz \\\n && NVSHMEM_SHMEM_SUPPORT=0 \\\n    NVSHMEM_UCX_SUPPORT=0 \\\n    NVSHMEM_USE_NCCL=0 \\\n    NVSHMEM_MPI_SUPPORT=0 \\\n    NVSHMEM_IBGDA_SUPPORT=1 \\\n    NVSHMEM_PMIX_SUPPORT=0 \\\n    NVSHMEM_TIMEOUT_DEVICE_POLLING=0 \\\n    NVSHMEM_USE_GDRCOPY=1 \\\n    cmake -S . -B build/ -DCMAKE_INSTALL_PREFIX=${NVSHMEM_DIR} -DCMAKE_CUDA_ARCHITECTURES=90 \\\n && cmake --build build --target install -j${CMAKE_BUILD_PARALLEL_LEVEL} \\\n && cd /sgl-workspace/DeepEP \\\n && NVSHMEM_DIR=${NVSHMEM_DIR} pip install .\n\n# Python tools\nRUN python3 -m pip install --no-cache-dir \\\n    datamodel_code_generator \\\n    mooncake-transfer-engine==0.3.5 \\\n    pre-commit \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    uv \\\n    wheel \\\n    scikit-build-core\n\n# Install development tools and utilities\nRUN apt-get update && apt-get install -y \\\n    gdb \\\n    ninja-build \\\n    vim \\\n    tmux \\\n    htop \\\n    wget \\\n    curl \\\n    locales \\\n    lsof \\\n    git \\\n    git-lfs \\\n    zsh \\\n    tree \\\n    silversearcher-ag \\\n    cloc \\\n    unzip \\\n    pkg-config \\\n    libssl-dev \\\n    bear \\\n    ccache \\\n    less \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt-get clean\n\nRUN apt update -y \\\n    && apt install -y --no-install-recommends gnupg \\\n    && echo \"deb http://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64 /\" | tee /etc/apt/sources.list.d/nvidia-devtools.list \\\n    && apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub \\\n    && apt update -y \\\n    && apt install nsight-systems-cli -y\n\n# Set up locale\nRUN locale-gen en_US.UTF-8\nENV LANG en_US.UTF-8\nENV LANGUAGE en_US:en\nENV LC_ALL en_US.UTF-8\n\n# Install minimal Python packages\nRUN python3 -m pip install --no-cache-dir --break-system-packages \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    scikit_build_core \\\n    uv \\\n    pre-commit \\\n    pandas \\\n    matplotlib \\\n    tabulate\n\n# Install diff-so-fancy\nRUN curl -LSso /usr/local/bin/diff-so-fancy https://github.com/so-fancy/diff-so-fancy/releases/download/v1.4.4/diff-so-fancy \\\n    && chmod +x /usr/local/bin/diff-so-fancy\n\n# Install clang-format\nRUN curl -LSso /usr/local/bin/clang-format https://github.com/muttleyxd/clang-tools-static-binaries/releases/download/master-32d3ac78/clang-format-16_linux-amd64 \\\n    && chmod +x /usr/local/bin/clang-format\n\n# Install clangd\nRUN curl -L https://github.com/clangd/clangd/releases/download/18.1.3/clangd-linux-18.1.3.zip -o clangd.zip \\\n    && unzip clangd.zip \\\n    && cp -r clangd_18.1.3/bin/* /usr/local/bin/ \\\n    && cp -r clangd_18.1.3/lib/* /usr/local/lib/ \\\n    && rm -rf clangd_18.1.3 clangd.zip\n\n# Install CMake\nRUN wget https://github.com/Kitware/CMake/releases/download/v3.31.1/cmake-3.31.1-linux-x86_64.tar.gz \\\n    && tar -xzf cmake-3.31.1-linux-x86_64.tar.gz \\\n    && cp -r cmake-3.31.1-linux-x86_64/bin/* /usr/local/bin/ \\\n    && cp -r cmake-3.31.1-linux-x86_64/share/* /usr/local/share/ \\\n    && rm -rf cmake-3.31.1-linux-x86_64 cmake-3.31.1-linux-x86_64.tar.gz\n\n# Add yank script\nCOPY --chown=root:root <<-\"EOF\" /usr/local/bin/yank\n#!/bin/bash\nput() {\n  esc=$1\n  test -n \"$TMUX\" -o -z \"${TERM##screen*}\" && esc=\"\\033Ptmux;\\033$esc\\033\\\\\"\n  printf \"$esc\"\n}\nput \"\\033]52;c;!\\a\"\nbuf=$( cat \"$@\" )\nlen=$( printf %s \"$buf\" | wc -c ) max=74994\ntest $len -gt $max && echo \"$0: input is $(( len - max )) bytes too long\" >&2\nput \"\\033]52;c;$( printf %s \"$buf\" | head -c $max | base64 | tr -d '\\r\\n' )\\a\"\ntest -n \"$TMUX\" && tmux set-buffer \"$buf\" ||:\nEOF\n\nRUN chmod +x /usr/local/bin/yank\n\n# Install oh-my-zsh and plugins\nRUN sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" \"\" --unattended \\\n    && git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions \\\n    && git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\n# Configure Vim\nCOPY --chown=root:root <<-\"EOF\" /root/.vimrc\nfunction! Yank(text) abort\n  let escape = system('yank', a:text)\n  if v:shell_error\n    echoerr escape\n  else\n    call writefile([escape], '/dev/tty', 'b')\n  endif\nendfunction\n\nnoremap <silent> <Leader>y y:<C-U>call Yank(@0)<CR>\n\n\" automatically run yank(1) whenever yanking in Vim\nfunction! CopyYank() abort\n  call Yank(join(v:event.regcontents, \"\\n\"))\nendfunction\n\nautocmd TextYankPost * call CopyYank()\n\n\" Basic settings\nset number\nsyntax on\nset mouse=a\nfiletype indent on\n\n\" Indentation\nset autoindent nosmartindent\nset smarttab\nset expandtab\nset shiftwidth=4\nset softtabstop=4\n\n\" Visual guides\nset colorcolumn=120\nhighlight ColorColumn ctermbg=5\n\n\" Status line\nset laststatus=2\nset statusline=%<%f\\ %h%m%r%=%{\\\"[\\\".(&fenc==\\\"\\\"?&enc:&fenc).((exists(\\\"+bomb\\\")\\ &&\\ &bomb)?\\\",B\\\":\\\"\\\").\\\"]\\ \\\"}%k\\ %-14.(%l,%c%V%)\\ %P\n\n\" Backspace behavior\nset backspace=2\n\n\" Encoding\nset encoding=utf-8\nset fileencoding=utf-8\nEOF\n\n# Configure tmux\nCOPY --chown=root:root <<-\"EOF\" /root/.tmux.conf\n# Pane border styling\nset -g pane-border-style fg='#742727',bg=black\nset -g pane-active-border-style fg=red,bg=black\n\n# Status bar styling\nset -g status-style bg='#0C8A92',fg=black\n\n# Change prefix key to backtick\nset-option -g prefix `\nunbind C-b\nbind-key ` send-prefix\n\n# Split panes using - and = with current path\nunbind '\"'\nbind - splitw -v -c '#{pane_current_path}'\nunbind '%'\nbind = splitw -h -c '#{pane_current_path}'\n\n# Vi mode settings\nbind-key -T copy-mode-vi Y send-keys -X copy-pipe 'yank > #{pane_tty}'\nset-window-option -g mode-keys vi\n\n# Other settings\nset-option -g escape-time 0\nset-option -g base-index 1\nset-window-option -g mouse on\nEOF\n\n# Configure Git\nRUN git config --global core.editor \"vim\" \\\n    && git config --global core.whitespace \"fix,-indent-with-non-tab,trailing-space,cr-at-eol\" \\\n    && git config --global core.pager \"diff-so-fancy | less --tabs=4 -RFX\" \\\n    && git config --global color.ui true \\\n    && git config --global color.\"diff-highlight\".oldNormal \"red bold\" \\\n    && git config --global color.\"diff-highlight\".oldHighlight \"red bold 52\" \\\n    && git config --global color.\"diff-highlight\".newNormal \"green bold\" \\\n    && git config --global color.\"diff-highlight\".newHighlight \"green bold 22\" \\\n    && git config --global color.diff.meta \"11\" \\\n    && git config --global color.diff.frag \"magenta bold\" \\\n    && git config --global color.diff.commit \"yellow bold\" \\\n    && git config --global color.diff.old \"red bold\" \\\n    && git config --global color.diff.new \"green bold\" \\\n    && git config --global color.diff.whitespace \"red reverse\" \\\n    && git config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset - %s %Cgreen(%cr) %C(bold blue)<%an>%Creset%C(auto)%d%Creset' --abbrev-commit --\" \\\n    && git config --global http.sslVerify false \\\n    && git config --global pull.rebase true\n\n# Configure zsh\nCOPY --chown=root:root <<-\"EOF\" /root/.zshrc\nexport ZSH=\"/root/.oh-my-zsh\"\n\n# Theme\nZSH_THEME=\"robbyrussell\"\n\n# Plugins\nplugins=(\n    git\n    z\n    zsh-autosuggestions\n    zsh-syntax-highlighting\n)\n\nsource $ZSH/oh-my-zsh.sh\n\n# Aliases\nalias ll='ls -alF'\nalias la='ls -A'\nalias l='ls -CF'\nalias vi='vim'\n\n# Enhanced history\nHISTSIZE=10000\nSAVEHIST=10000\nsetopt HIST_IGNORE_ALL_DUPS\nsetopt HIST_FIND_NO_DUPS\nsetopt INC_APPEND_HISTORY\nEOF\n\nRUN set -euxo ; \\\n    curl --proto '=https' --tlsv1.2 -sSf https://just.systems/install.sh | bash -s -- --to /usr/local/bin\n\n# Set workspace directory\nWORKDIR /sgl-workspace/sglang\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.6.1\nFROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04\n\nARG BUILD_TYPE=all\nARG DEEPEP_COMMIT=b6ce310bb0b75079682d09bc2ebc063a074fbd58\nARG CMAKE_BUILD_PARALLEL_LEVEL=2\nENV DEBIAN_FRONTEND=noninteractive \\\n    CUDA_HOME=/usr/local/cuda \\\n    GDRCOPY_HOME=/usr/src/gdrdrv-2.4.4/ \\\n    NVSHMEM_DIR=/sgl-workspace/nvshmem/install\n\n# Set timezone and install all packages\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n && apt-get update && apt-get install -y --no-install-recommends \\\n    tzdata \\\n    software-properties-common netcat-openbsd kmod unzip openssh-server \\\n    curl wget lsof zsh ccache tmux htop git-lfs tree \\\n    python3 python3-pip python3-dev libpython3-dev python3-venv \\\n    build-essential cmake \\\n    libopenmpi-dev libnuma1 libnuma-dev \\\n    libibverbs-dev libibverbs1 libibumad3 \\\n    librdmacm1 libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnl-3-dev \\\n    ibverbs-providers infiniband-diags perftest \\\n    libgoogle-glog-dev libgtest-dev libjsoncpp-dev libunwind-dev \\\n    libboost-all-dev libssl-dev \\\n    libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc \\\n    pybind11-dev \\\n    libhiredis-dev libcurl4-openssl-dev \\\n    libczmq4 libczmq-dev \\\n    libfabric-dev \\\n    patchelf \\\n    nvidia-dkms-550 \\\n    devscripts debhelper fakeroot dkms check libsubunit0 libsubunit-dev \\\n && ln -sf /usr/bin/python3 /usr/bin/python \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# GDRCopy installation\nRUN mkdir -p /tmp/gdrcopy && cd /tmp \\\n && git clone https://github.com/NVIDIA/gdrcopy.git -b v2.4.4 \\\n && cd gdrcopy/packages \\\n && CUDA=/usr/local/cuda ./build-deb-packages.sh \\\n && dpkg -i gdrdrv-dkms_*.deb libgdrapi_*.deb gdrcopy-tests_*.deb gdrcopy_*.deb \\\n && cd / && rm -rf /tmp/gdrcopy\n\n# Fix DeepEP IBGDA symlink\nRUN ln -sf /usr/lib/x86_64-linux-gnu/libmlx5.so.1 /usr/lib/x86_64-linux-gnu/libmlx5.so\n\n# Clone and install SGLang\nWORKDIR /sgl-workspace\nRUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel html5lib six \\\n && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n && cd sglang \\\n && case \"$CUDA_VERSION\" in \\\n      12.6.1) CUINDEX=126 ;; \\\n      12.8.1) CUINDEX=128 ;; \\\n      *) echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1 ;; \\\n    esac \\\n && python3 -m pip install --no-cache-dir -e \"python[${BUILD_TYPE}]\" --extra-index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n && python3 -m pip install --no-cache-dir nvidia-nccl-cu12==2.27.6 --force-reinstall --no-deps \\\n && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n      python3 -m pip install --no-cache-dir https://github.com/sgl-project/whl/releases/download/v0.2.7/sgl_kernel-0.2.7+cu128-cp39-abi3-manylinux2014_x86_64.whl --force-reinstall --no-deps ; \\\n    fi\n\n# Build and install NVSHMEM + DeepEP\nRUN wget https://developer.download.nvidia.com/compute/redist/nvshmem/3.3.9/source/nvshmem_src_cuda12-all-all-3.3.9.tar.gz \\\n && git clone https://github.com/deepseek-ai/DeepEP.git \\\n && cd DeepEP && git checkout ${DEEPEP_COMMIT} && cd .. \\\n && tar -xf nvshmem_src_cuda12-all-all-3.3.9.tar.gz && mv nvshmem_src nvshmem \\\n && cd nvshmem \\\n && rm -f /sgl-workspace/nvshmem_src_cuda12-all-all-3.3.9.tar.gz \\\n && NVSHMEM_SHMEM_SUPPORT=0 \\\n    NVSHMEM_UCX_SUPPORT=0 \\\n    NVSHMEM_USE_NCCL=0 \\\n    NVSHMEM_MPI_SUPPORT=0 \\\n    NVSHMEM_IBGDA_SUPPORT=1 \\\n    NVSHMEM_PMIX_SUPPORT=0 \\\n    NVSHMEM_TIMEOUT_DEVICE_POLLING=0 \\\n    NVSHMEM_USE_GDRCOPY=1 \\\n    cmake -S . -B build/ -DCMAKE_INSTALL_PREFIX=${NVSHMEM_DIR} -DCMAKE_CUDA_ARCHITECTURES=90 \\\n && cmake --build build --target install -j${CMAKE_BUILD_PARALLEL_LEVEL} \\\n && cd /sgl-workspace/DeepEP \\\n && NVSHMEM_DIR=${NVSHMEM_DIR} pip install .\n\n# Python tools\nRUN python3 -m pip install --no-cache-dir \\\n    datamodel_code_generator \\\n    mooncake-transfer-engine==0.3.5 \\\n    pre-commit \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    uv \\\n    wheel \\\n    scikit-build-core\n\n# Install development tools and utilities\nRUN apt-get update && apt-get install -y \\\n    gdb \\\n    ninja-build \\\n    vim \\\n    tmux \\\n    htop \\\n    wget \\\n    curl \\\n    locales \\\n    lsof \\\n    git \\\n    git-lfs \\\n    zsh \\\n    tree \\\n    silversearcher-ag \\\n    cloc \\\n    unzip \\\n    pkg-config \\\n    libssl-dev \\\n    bear \\\n    ccache \\\n    less \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt-get clean\n\nRUN apt update -y \\\n    && apt install -y --no-install-recommends gnupg \\\n    && echo \"deb http://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64 /\" | tee /etc/apt/sources.list.d/nvidia-devtools.list \\\n    && apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub \\\n    && apt update -y \\\n    && apt install nsight-systems-cli -y\n\n# Set up locale\nRUN locale-gen en_US.UTF-8\nENV LANG en_US.UTF-8\nENV LANGUAGE en_US:en\nENV LC_ALL en_US.UTF-8\n\n# Install minimal Python packages\nRUN python3 -m pip install --no-cache-dir --break-system-packages \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    scikit_build_core \\\n    uv \\\n    pre-commit \\\n    pandas \\\n    matplotlib \\\n    tabulate\n\n# Install diff-so-fancy\nRUN curl -LSso /usr/local/bin/diff-so-fancy https://github.com/so-fancy/diff-so-fancy/releases/download/v1.4.4/diff-so-fancy \\\n    && chmod +x /usr/local/bin/diff-so-fancy\n\n# Install clang-format\nRUN curl -LSso /usr/local/bin/clang-format https://github.com/muttleyxd/clang-tools-static-binaries/releases/download/master-32d3ac78/clang-format-16_linux-amd64 \\\n    && chmod +x /usr/local/bin/clang-format\n\n# Install clangd\nRUN curl -L https://github.com/clangd/clangd/releases/download/18.1.3/clangd-linux-18.1.3.zip -o clangd.zip \\\n    && unzip clangd.zip \\\n    && cp -r clangd_18.1.3/bin/* /usr/local/bin/ \\\n    && cp -r clangd_18.1.3/lib/* /usr/local/lib/ \\\n    && rm -rf clangd_18.1.3 clangd.zip\n\n# Install CMake\nRUN wget https://github.com/Kitware/CMake/releases/download/v3.31.1/cmake-3.31.1-linux-x86_64.tar.gz \\\n    && tar -xzf cmake-3.31.1-linux-x86_64.tar.gz \\\n    && cp -r cmake-3.31.1-linux-x86_64/bin/* /usr/local/bin/ \\\n    && cp -r cmake-3.31.1-linux-x86_64/share/* /usr/local/share/ \\\n    && rm -rf cmake-3.31.1-linux-x86_64 cmake-3.31.1-linux-x86_64.tar.gz\n\n# Add yank script\nCOPY --chown=root:root <<-\"EOF\" /usr/local/bin/yank\n#!/bin/bash\nput() {\n  esc=$1\n  test -n \"$TMUX\" -o -z \"${TERM##screen*}\" && esc=\"\\033Ptmux;\\033$esc\\033\\\\\"\n  printf \"$esc\"\n}\nput \"\\033]52;c;!\\a\"\nbuf=$( cat \"$@\" )\nlen=$( printf %s \"$buf\" | wc -c ) max=74994\ntest $len -gt $max && echo \"$0: input is $(( len - max )) bytes too long\" >&2\nput \"\\033]52;c;$( printf %s \"$buf\" | head -c $max | base64 | tr -d '\\r\\n' )\\a\"\ntest -n \"$TMUX\" && tmux set-buffer \"$buf\" ||:\nEOF\n\nRUN chmod +x /usr/local/bin/yank\n\n# Install oh-my-zsh and plugins\nRUN sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" \"\" --unattended \\\n    && git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions \\\n    && git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\n# Configure Vim\nCOPY --chown=root:root <<-\"EOF\" /root/.vimrc\nfunction! Yank(text) abort\n  let escape = system('yank', a:text)\n  if v:shell_error\n    echoerr escape\n  else\n    call writefile([escape], '/dev/tty', 'b')\n  endif\nendfunction\n\nnoremap <silent> <Leader>y y:<C-U>call Yank(@0)<CR>\n\n\" automatically run yank(1) whenever yanking in Vim\nfunction! CopyYank() abort\n  call Yank(join(v:event.regcontents, \"\\n\"))\nendfunction\n\nautocmd TextYankPost * call CopyYank()\n\n\" Basic settings\nset number\nsyntax on\nset mouse=a\nfiletype indent on\n\n\" Indentation\nset autoindent nosmartindent\nset smarttab\nset expandtab\nset shiftwidth=4\nset softtabstop=4\n\n\" Visual guides\nset colorcolumn=120\nhighlight ColorColumn ctermbg=5\n\n\" Status line\nset laststatus=2\nset statusline=%<%f\\ %h%m%r%=%{\\\"[\\\".(&fenc==\\\"\\\"?&enc:&fenc).((exists(\\\"+bomb\\\")\\ &&\\ &bomb)?\\\",B\\\":\\\"\\\").\\\"]\\ \\\"}%k\\ %-14.(%l,%c%V%)\\ %P\n\n\" Backspace behavior\nset backspace=2\n\n\" Encoding\nset encoding=utf-8\nset fileencoding=utf-8\nEOF\n\n# Configure tmux\nCOPY --chown=root:root <<-\"EOF\" /root/.tmux.conf\n# Pane border styling\nset -g pane-border-style fg='#742727',bg=black\nset -g pane-active-border-style fg=red,bg=black\n\n# Status bar styling\nset -g status-style bg='#0C8A92',fg=black\n\n# Change prefix key to backtick\nset-option -g prefix `\nunbind C-b\nbind-key ` send-prefix\n\n# Split panes using - and = with current path\nunbind '\"'\nbind - splitw -v -c '#{pane_current_path}'\nunbind '%'\nbind = splitw -h -c '#{pane_current_path}'\n\n# Vi mode settings\nbind-key -T copy-mode-vi Y send-keys -X copy-pipe 'yank > #{pane_tty}'\nset-window-option -g mode-keys vi\n\n# Other settings\nset-option -g escape-time 0\nset-option -g base-index 1\nset-window-option -g mouse on\nEOF\n\n# Configure Git\nRUN git config --global core.editor \"vim\" \\\n    && git config --global core.whitespace \"fix,-indent-with-non-tab,trailing-space,cr-at-eol\" \\\n    && git config --global core.pager \"diff-so-fancy | less --tabs=4 -RFX\" \\\n    && git config --global color.ui true \\\n    && git config --global color.\"diff-highlight\".oldNormal \"red bold\" \\\n    && git config --global color.\"diff-highlight\".oldHighlight \"red bold 52\" \\\n    && git config --global color.\"diff-highlight\".newNormal \"green bold\" \\\n    && git config --global color.\"diff-highlight\".newHighlight \"green bold 22\" \\\n    && git config --global color.diff.meta \"11\" \\\n    && git config --global color.diff.frag \"magenta bold\" \\\n    && git config --global color.diff.commit \"yellow bold\" \\\n    && git config --global color.diff.old \"red bold\" \\\n    && git config --global color.diff.new \"green bold\" \\\n    && git config --global color.diff.whitespace \"red reverse\" \\\n    && git config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset - %s %Cgreen(%cr) %C(bold blue)<%an>%Creset%C(auto)%d%Creset' --abbrev-commit --\" \\\n    && git config --global http.sslVerify false \\\n    && git config --global pull.rebase true\n\n# Configure zsh\nCOPY --chown=root:root <<-\"EOF\" /root/.zshrc\nexport ZSH=\"/root/.oh-my-zsh\"\n\n# Theme\nZSH_THEME=\"robbyrussell\"\n\n# Plugins\nplugins=(\n    git\n    z\n    zsh-autosuggestions\n    zsh-syntax-highlighting\n)\n\nsource $ZSH/oh-my-zsh.sh\n\n# Aliases\nalias ll='ls -alF'\nalias la='ls -A'\nalias l='ls -CF'\nalias vi='vim'\n\n# Enhanced history\nHISTSIZE=10000\nSAVEHIST=10000\nsetopt HIST_IGNORE_ALL_DUPS\nsetopt HIST_FIND_NO_DUPS\nsetopt INC_APPEND_HISTORY\nEOF\n\nRUN set -euxo ; \\\n    curl --proto '=https' --tlsv1.2 -sSf https://just.systems/install.sh | bash -s -- --to /usr/local/bin\n\n# Set workspace directory\nWORKDIR /sgl-workspace/sglang\n"}
{"commit_hash": "564a898ad975192b593be81387d11faf15cb1d3e", "commit_short": "564a898ad975", "commit_subject": "Optimize mem indices mangement (#619)", "pr_url": "https://github.com/sgl-project/sglang/pull/619", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Docker: Server timeout - no benchmark output received (old SGLang version)", "error_date": "2026-01-04", "parent_commit": "5d264a90ac5154d8e368ee558337dd3dd92e720b", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "FROM vllm/vllm-openai\n\nRUN pip install --upgrade pip\nRUN pip install \"sglang[all]\"\nRUN pip uninstall -y triton triton-nightly && pip install --no-deps --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/ triton-nightly\nRUN pip install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.3/\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "FROM vllm/vllm-openai\n\nRUN pip install --upgrade pip\nRUN pip install \"sglang[all]\"\nRUN pip uninstall -y triton triton-nightly && pip install --no-deps --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/ triton-nightly\nRUN pip install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.3/\n"}
{"commit_hash": "62757db6f0f09a6dff15b1ee1ac3029602951509", "commit_short": "62757db6f0f0", "commit_subject": "Reduce the overhead when cache is disabled (#1010)", "pr_url": "https://github.com/sgl-project/sglang/pull/1010", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Docker: flashinfer/torch ABI mismatch - rebuild image with matching versions", "error_date": "2026-01-04", "parent_commit": "73fa2d49d539fd67548b0458a365528d3e3b6edc", "human_only_success": true, "human_only_date": "2026-01-06", "human_throughput": 355.1, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\n\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\n\nARG PYTHON_VERSION=3\n\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt-get update -y \\\n    && apt-get install -y ccache software-properties-common \\\n    && add-apt-repository ppa:deadsnakes/ppa \\\n    && apt-get update -y \\\n    && apt-get install -y python${PYTHON_VERSION} python${PYTHON_VERSION}-dev python${PYTHON_VERSION}-venv python${PYTHON_VERSION}-pip \\\n    && if [ \"${PYTHON_VERSION}\" != \"3\" ]; then update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 1; fi \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt-get clean\n\nRUN apt-get update -y \\\n    && apt-get install -y git curl sudo\n\nWORKDIR /sgl-workspace\n\nRUN pip3 --no-cache-dir install --upgrade pip \\\n    && pip3 --no-cache-dir install --upgrade setuptools wheel \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && pip --no-cache-dir install -e \"python[all]\" \\\n    && pip3 --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\n\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\n\nARG PYTHON_VERSION=3\n\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt-get update -y \\\n    && apt-get install -y ccache software-properties-common \\\n    && add-apt-repository ppa:deadsnakes/ppa \\\n    && apt-get update -y \\\n    && apt-get install -y python${PYTHON_VERSION} python${PYTHON_VERSION}-dev python${PYTHON_VERSION}-venv python${PYTHON_VERSION}-pip \\\n    && if [ \"${PYTHON_VERSION}\" != \"3\" ]; then update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 1; fi \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt-get clean\n\nRUN apt-get update -y \\\n    && apt-get install -y git curl sudo\n\nWORKDIR /sgl-workspace\n\nRUN pip3 --no-cache-dir install --upgrade pip \\\n    && pip3 --no-cache-dir install --upgrade setuptools wheel \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && pip --no-cache-dir install -e \"python[all]\" \\\n    && pip3 --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "6a2941f4d037cb5fa7c927342dc7f09387c29ab0", "commit_short": "6a2941f4d037", "commit_subject": "Improve tensor parallel performance (#625)", "pr_url": "https://github.com/sgl-project/sglang/pull/625", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Docker: Server timeout - no benchmark output received (old SGLang version)", "error_date": "2026-01-04", "parent_commit": "5ac8b80677614a9c024740e94f9a087a39eb3499", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "FROM vllm/vllm-openai\n\nRUN pip install --upgrade pip\nRUN pip install \"sglang[all]\"\nRUN pip uninstall -y triton triton-nightly && pip install --no-deps --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/ triton-nightly\nRUN pip install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.3/\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "FROM vllm/vllm-openai\n\nRUN pip install --upgrade pip\nRUN pip install \"sglang[all]\"\nRUN pip uninstall -y triton triton-nightly && pip install --no-deps --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/ triton-nightly\nRUN pip install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.3/\n"}
{"commit_hash": "6b231325b9782555eb8e1cfcf27820003a98382b", "commit_short": "6b231325b978", "commit_subject": "[PD Perf] replace Queue to FastQueue (#6649)", "pr_url": "https://github.com/sgl-project/sglang/pull/6649", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "b1c8d4e9f31953560f2db45a3b6e68099ef00c13", "human_throughput": 1555.5, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "6cb00c6398126513e37c43dd975d461765fb44c7", "commit_short": "6cb00c639812", "commit_subject": "[PD] Optimize time out logic and add env var doc for mooncake (#6761)", "pr_url": "https://github.com/sgl-project/sglang/pull/6761", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "62cac2c43abb7c2d00be3b93581ab50ab1562a10", "human_throughput": 1543.5, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "benchmark_note": "INVALID BENCHMARK: This PR optimizes Mooncake PD Disaggregation timeout logic. Standard bench_serving does not exercise this code path. Requires --disaggregation-mode and --disaggregation-transfer-backend mooncake with multi-node setup. Baseline outperformed human/agent because the optimization only affects disaggregated serving.", "benchmark_invalid": true, "requires_special_setup": "PD disaggregation with Mooncake backend", "3way_benchmark_date": "2026-01-06", "3way_baseline_throughput": 1590.25, "3way_human_throughput": 1551.49, "3way_agent_throughput": 1563.26, "3way_result": "baseline_best"}
{"commit_hash": "6e2da5156176ed2d7fe2445b7c7316bc1650b20a", "commit_short": "6e2da5156176", "commit_subject": "Replace time.time() to time.perf_counter() for benchmarking. (#6178)", "pr_url": "https://github.com/sgl-project/sglang/pull/6178", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "e9a47f4cb58a5a2fedd7843211684b8e4db3c0c5", "human_throughput": 1558.2, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "6f560c761b2fc2f577682d0cfda62630f37a3bb0", "commit_short": "6f560c761b2f", "commit_subject": "Improve the control of streaming and improve the first token latency in streaming (#117)", "pr_url": "https://github.com/sgl-project/sglang/pull/117", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "error": "Base Docker image cd6872334e9ead684049b8fccd5f2dac9433b1b4 broken - missing torch and core dependencies (early sglang commit before proper packaging)", "error_date": "2026-01-04", "parent_commit": "cd6872334e9ead684049b8fccd5f2dac9433b1b4", "human_throughput": 1623.1, "has_dockerfile": false, "dockerfile_path": null, "dockerfile_content": null, "parent_has_dockerfile": false, "parent_dockerfile_path": null, "parent_dockerfile_content": null}
{"commit_hash": "6fc175968c3a9fc0521948aa3636887cd6d84107", "commit_short": "6fc175968c3a", "commit_subject": "Optimize a pad operation to accelerate 25us (#5945)", "pr_url": "https://github.com/sgl-project/sglang/pull/5945", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Server failed to start", "error_date": "2026-01-06", "parent_commit": "ad506a4e6bf3d9ac12100d4648c48df76f584c4e", "human_only_success": false, "human_only_date": "2026-01-06", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "73b13e69b4207f240650c6b51eba7a7204f64939", "commit_short": "73b13e69b420", "commit_subject": "Optimize DP attn scheduling for speculative decoding (#7285)", "pr_url": "https://github.com/sgl-project/sglang/pull/7285", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "8609e637a961dd0bd17bbf7f8f81b34cb2f7863a", "human_throughput": 1503.8, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.6.1\nFROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive \\\n    CUDA_HOME=/usr/local/cuda \\\n    GDRCOPY_HOME=/usr/src/gdrdrv-2.4.4/ \\\n    NVSHMEM_DIR=/sgl-workspace/nvshmem/install\n\n# Set timezone and install all packages\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n && apt-get update && apt-get install -y --no-install-recommends \\\n    tzdata \\\n    software-properties-common netcat-openbsd kmod unzip openssh-server \\\n    curl wget lsof zsh ccache tmux htop git-lfs tree \\\n    python3 python3-pip python3-dev libpython3-dev \\\n    build-essential cmake \\\n    libopenmpi-dev libnuma1 libnuma-dev \\\n    libibverbs-dev libibverbs1 libibumad3 \\\n    librdmacm1 libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnl-3-dev \\\n    ibverbs-providers infiniband-diags perftest \\\n    libgoogle-glog-dev libgtest-dev libjsoncpp-dev libunwind-dev \\\n    libboost-all-dev libssl-dev \\\n    libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc \\\n    pybind11-dev \\\n    libhiredis-dev libcurl4-openssl-dev \\\n    libczmq4 libczmq-dev \\\n    libfabric-dev \\\n    patchelf \\\n    nvidia-dkms-550 \\\n    devscripts debhelper fakeroot dkms check libsubunit0 libsubunit-dev \\\n && ln -sf /usr/bin/python3 /usr/bin/python \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# GDRCopy installation\nRUN mkdir -p /tmp/gdrcopy && cd /tmp \\\n && git clone https://github.com/NVIDIA/gdrcopy.git -b v2.4.4 \\\n && cd gdrcopy/packages \\\n && CUDA=/usr/local/cuda ./build-deb-packages.sh \\\n && dpkg -i gdrdrv-dkms_*.deb libgdrapi_*.deb gdrcopy-tests_*.deb gdrcopy_*.deb \\\n && cd / && rm -rf /tmp/gdrcopy\n\n# Fix DeepEP IBGDA symlink\nRUN ln -sf /usr/lib/x86_64-linux-gnu/libmlx5.so.1 /usr/lib/x86_64-linux-gnu/libmlx5.so\n\n# Clone and install SGLang\nWORKDIR /sgl-workspace\nRUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel html5lib six \\\n && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n && cd sglang \\\n && case \"$CUDA_VERSION\" in \\\n      12.6.1) CUINDEX=126 ;; \\\n      12.8.1) CUINDEX=128 ;; \\\n      *) echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1 ;; \\\n    esac \\\n && python3 -m pip install --no-cache-dir -e \"python[${BUILD_TYPE}]\" --extra-index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n      python3 -m pip install --no-cache-dir nvidia-nccl-cu12==2.27.3 --force-reinstall --no-deps ; \\\n      python3 -m pip install --no-cache-dir https://github.com/sgl-project/whl/releases/download/v0.1.9/sgl_kernel-0.1.9+cu128-cp39-abi3-manylinux2014_x86_64.whl --force-reinstall --no-deps ; \\\n    fi\n\n# Build and install NVSHMEM + DeepEP\nRUN wget https://developer.download.nvidia.com/compute/redist/nvshmem/3.2.5/source/nvshmem_src_3.2.5-1.txz \\\n && git clone https://github.com/deepseek-ai/DeepEP.git \\\n && tar -xf nvshmem_src_3.2.5-1.txz && mv nvshmem_src nvshmem \\\n && cd nvshmem \\\n && git apply /sgl-workspace/DeepEP/third-party/nvshmem.patch \\\n && sed -i '1i#include <unistd.h>' examples/moe_shuffle.cu \\\n && rm -f /sgl-workspace/nvshmem_src_3.2.5-1.txz \\\n && NVSHMEM_SHMEM_SUPPORT=0 \\\n    NVSHMEM_UCX_SUPPORT=0 \\\n    NVSHMEM_USE_NCCL=0 \\\n    NVSHMEM_MPI_SUPPORT=0 \\\n    NVSHMEM_IBGDA_SUPPORT=1 \\\n    NVSHMEM_PMIX_SUPPORT=0 \\\n    NVSHMEM_TIMEOUT_DEVICE_POLLING=0 \\\n    NVSHMEM_USE_GDRCOPY=1 \\\n    cmake -S . -B build/ -DCMAKE_INSTALL_PREFIX=${NVSHMEM_DIR} -DCMAKE_CUDA_ARCHITECTURES=90 \\\n && cmake --build build --target install -j \\\n && cd /sgl-workspace/DeepEP \\\n && NVSHMEM_DIR=${NVSHMEM_DIR} pip install .\n\n# Python tools\nRUN python3 -m pip install --no-cache-dir \\\n    datamodel_code_generator \\\n    mooncake_transfer_engine==0.3.3.post2 \\\n    pre-commit \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    uv \\\n    wheel \\\n    scikit-build-core\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.6.1\nFROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive \\\n    CUDA_HOME=/usr/local/cuda \\\n    GDRCOPY_HOME=/usr/src/gdrdrv-2.4.4/ \\\n    NVSHMEM_DIR=/sgl-workspace/nvshmem/install\n\n# Set timezone and install all packages\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n && apt-get update && apt-get install -y --no-install-recommends \\\n    tzdata \\\n    software-properties-common netcat-openbsd kmod unzip openssh-server \\\n    curl wget lsof zsh ccache tmux htop git-lfs tree \\\n    python3 python3-pip python3-dev libpython3-dev \\\n    build-essential cmake \\\n    libopenmpi-dev libnuma1 libnuma-dev \\\n    libibverbs-dev libibverbs1 libibumad3 \\\n    librdmacm1 libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnl-3-dev \\\n    ibverbs-providers infiniband-diags perftest \\\n    libgoogle-glog-dev libgtest-dev libjsoncpp-dev libunwind-dev \\\n    libboost-all-dev libssl-dev \\\n    libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc \\\n    pybind11-dev \\\n    libhiredis-dev libcurl4-openssl-dev \\\n    libczmq4 libczmq-dev \\\n    libfabric-dev \\\n    patchelf \\\n    nvidia-dkms-550 \\\n    devscripts debhelper fakeroot dkms check libsubunit0 libsubunit-dev \\\n && ln -sf /usr/bin/python3 /usr/bin/python \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# GDRCopy installation\nRUN mkdir -p /tmp/gdrcopy && cd /tmp \\\n && git clone https://github.com/NVIDIA/gdrcopy.git -b v2.4.4 \\\n && cd gdrcopy/packages \\\n && CUDA=/usr/local/cuda ./build-deb-packages.sh \\\n && dpkg -i gdrdrv-dkms_*.deb libgdrapi_*.deb gdrcopy-tests_*.deb gdrcopy_*.deb \\\n && cd / && rm -rf /tmp/gdrcopy\n\n# Fix DeepEP IBGDA symlink\nRUN ln -sf /usr/lib/x86_64-linux-gnu/libmlx5.so.1 /usr/lib/x86_64-linux-gnu/libmlx5.so\n\n# Clone and install SGLang\nWORKDIR /sgl-workspace\nRUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel html5lib six \\\n && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n && cd sglang \\\n && case \"$CUDA_VERSION\" in \\\n      12.6.1) CUINDEX=126 ;; \\\n      12.8.1) CUINDEX=128 ;; \\\n      *) echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1 ;; \\\n    esac \\\n && python3 -m pip install --no-cache-dir -e \"python[${BUILD_TYPE}]\" --extra-index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n      python3 -m pip install --no-cache-dir nvidia-nccl-cu12==2.27.3 --force-reinstall --no-deps ; \\\n      python3 -m pip install --no-cache-dir https://github.com/sgl-project/whl/releases/download/v0.1.9/sgl_kernel-0.1.9+cu128-cp39-abi3-manylinux2014_x86_64.whl --force-reinstall --no-deps ; \\\n    fi\n\n# Build and install NVSHMEM + DeepEP\nRUN wget https://developer.download.nvidia.com/compute/redist/nvshmem/3.2.5/source/nvshmem_src_3.2.5-1.txz \\\n && git clone https://github.com/deepseek-ai/DeepEP.git \\\n && tar -xf nvshmem_src_3.2.5-1.txz && mv nvshmem_src nvshmem \\\n && cd nvshmem \\\n && git apply /sgl-workspace/DeepEP/third-party/nvshmem.patch \\\n && sed -i '1i#include <unistd.h>' examples/moe_shuffle.cu \\\n && rm -f /sgl-workspace/nvshmem_src_3.2.5-1.txz \\\n && NVSHMEM_SHMEM_SUPPORT=0 \\\n    NVSHMEM_UCX_SUPPORT=0 \\\n    NVSHMEM_USE_NCCL=0 \\\n    NVSHMEM_MPI_SUPPORT=0 \\\n    NVSHMEM_IBGDA_SUPPORT=1 \\\n    NVSHMEM_PMIX_SUPPORT=0 \\\n    NVSHMEM_TIMEOUT_DEVICE_POLLING=0 \\\n    NVSHMEM_USE_GDRCOPY=1 \\\n    cmake -S . -B build/ -DCMAKE_INSTALL_PREFIX=${NVSHMEM_DIR} -DCMAKE_CUDA_ARCHITECTURES=90 \\\n && cmake --build build --target install -j \\\n && cd /sgl-workspace/DeepEP \\\n && NVSHMEM_DIR=${NVSHMEM_DIR} pip install .\n\n# Python tools\nRUN python3 -m pip install --no-cache-dir \\\n    datamodel_code_generator \\\n    mooncake_transfer_engine==0.3.3.post2 \\\n    pre-commit \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    uv \\\n    wheel \\\n    scikit-build-core\n\nENV DEBIAN_FRONTEND=interactive\n", "benchmark_note": "INVALID BENCHMARK: This PR optimizes DP attention scheduling for speculative decoding. Standard bench_serving does not enable speculative decoding, so the optimization is not exercised. Requires --speculative-* flags to test this optimization. Baseline outperformed human/agent in standard benchmark.", "benchmark_invalid": true, "requires_special_setup": "Speculative decoding with --speculative-algorithm, --speculative-draft-model-path flags", "3way_benchmark_date": "2026-01-06", "3way_baseline_throughput": 1622.92, "3way_human_throughput": 1621.7, "3way_agent_throughput": 1616.82, "3way_result": "baseline_best"}
{"commit_hash": "79961afa8281f98f380d11db45c8d4b6e66a574f", "commit_short": "79961afa8281", "commit_subject": "optimize pad operations in fa3 to accelarate 100+us (#6077)", "pr_url": "https://github.com/sgl-project/sglang/pull/6077", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Server failed to start", "error_date": "2026-01-06", "parent_commit": "cfca4e0ed2cf4a97c2ee3b668f7115b59db0028a", "human_only_success": false, "human_only_date": "2026-01-06", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "7ce36068914503c3a53ad7be23ab29831fb8aa63", "commit_short": "7ce360689145", "commit_subject": "Faster overlap mode scheduler (#1738)", "pr_url": "https://github.com/sgl-project/sglang/pull/1738", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python3 -m sglang.bench_serving --model meta-llama/Llama-3.1-8B-Instruct --num-prompt 3000 --disable-radix --enable-overlap", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Server failed to start", "error_date": "2026-01-06", "parent_commit": "efb099cdee90b9ad332fcda96d89dd91ddebe072", "human_only_success": false, "human_only_date": "2026-01-06", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "880221bd3b3e56a4bc2268fe9a9f77f426accf6c", "commit_short": "880221bd3b3e", "commit_subject": "Revert \"[PD Disaggregation] replace transfer with batch transfer for better performance (#7236)\" (#7968)", "pr_url": "https://github.com/sgl-project/sglang/pull/7968", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "8f3173d0b0721acc94a39fb654eb46a4f298958d", "human_throughput": 1624.8, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.6.1\nFROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive \\\n    CUDA_HOME=/usr/local/cuda \\\n    GDRCOPY_HOME=/usr/src/gdrdrv-2.4.4/ \\\n    NVSHMEM_DIR=/sgl-workspace/nvshmem/install\n\n# Set timezone and install all packages\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n && apt-get update && apt-get install -y --no-install-recommends \\\n    tzdata \\\n    software-properties-common netcat-openbsd kmod unzip openssh-server \\\n    curl wget lsof zsh ccache tmux htop git-lfs tree \\\n    python3 python3-pip python3-dev libpython3-dev \\\n    build-essential cmake \\\n    libopenmpi-dev libnuma1 libnuma-dev \\\n    libibverbs-dev libibverbs1 libibumad3 \\\n    librdmacm1 libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnl-3-dev \\\n    ibverbs-providers infiniband-diags perftest \\\n    libgoogle-glog-dev libgtest-dev libjsoncpp-dev libunwind-dev \\\n    libboost-all-dev libssl-dev \\\n    libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc \\\n    pybind11-dev \\\n    libhiredis-dev libcurl4-openssl-dev \\\n    libczmq4 libczmq-dev \\\n    libfabric-dev \\\n    patchelf \\\n    nvidia-dkms-550 \\\n    devscripts debhelper fakeroot dkms check libsubunit0 libsubunit-dev \\\n && ln -sf /usr/bin/python3 /usr/bin/python \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# GDRCopy installation\nRUN mkdir -p /tmp/gdrcopy && cd /tmp \\\n && git clone https://github.com/NVIDIA/gdrcopy.git -b v2.4.4 \\\n && cd gdrcopy/packages \\\n && CUDA=/usr/local/cuda ./build-deb-packages.sh \\\n && dpkg -i gdrdrv-dkms_*.deb libgdrapi_*.deb gdrcopy-tests_*.deb gdrcopy_*.deb \\\n && cd / && rm -rf /tmp/gdrcopy\n\n# Fix DeepEP IBGDA symlink\nRUN ln -sf /usr/lib/x86_64-linux-gnu/libmlx5.so.1 /usr/lib/x86_64-linux-gnu/libmlx5.so\n\n# Clone and install SGLang\nWORKDIR /sgl-workspace\nRUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel html5lib six \\\n && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n && cd sglang \\\n && case \"$CUDA_VERSION\" in \\\n      12.6.1) CUINDEX=126 ;; \\\n      12.8.1) CUINDEX=128 ;; \\\n      *) echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1 ;; \\\n    esac \\\n && python3 -m pip install --no-cache-dir -e \"python[${BUILD_TYPE}]\" --extra-index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n      python3 -m pip install --no-cache-dir nvidia-nccl-cu12==2.27.5 --force-reinstall --no-deps ; \\\n      python3 -m pip install --no-cache-dir https://github.com/sgl-project/whl/releases/download/v0.2.5/sgl_kernel-0.2.5+cu128-cp39-abi3-manylinux2014_x86_64.whl --force-reinstall --no-deps ; \\\n    fi\n\n# Build and install NVSHMEM + DeepEP\nRUN wget https://developer.download.nvidia.com/compute/redist/nvshmem/3.2.5/source/nvshmem_src_3.2.5-1.txz \\\n && git clone https://github.com/deepseek-ai/DeepEP.git \\\n && tar -xf nvshmem_src_3.2.5-1.txz && mv nvshmem_src nvshmem \\\n && cd nvshmem \\\n && git apply /sgl-workspace/DeepEP/third-party/nvshmem.patch \\\n && sed -i '1i#include <unistd.h>' examples/moe_shuffle.cu \\\n && rm -f /sgl-workspace/nvshmem_src_3.2.5-1.txz \\\n && NVSHMEM_SHMEM_SUPPORT=0 \\\n    NVSHMEM_UCX_SUPPORT=0 \\\n    NVSHMEM_USE_NCCL=0 \\\n    NVSHMEM_MPI_SUPPORT=0 \\\n    NVSHMEM_IBGDA_SUPPORT=1 \\\n    NVSHMEM_PMIX_SUPPORT=0 \\\n    NVSHMEM_TIMEOUT_DEVICE_POLLING=0 \\\n    NVSHMEM_USE_GDRCOPY=1 \\\n    cmake -S . -B build/ -DCMAKE_INSTALL_PREFIX=${NVSHMEM_DIR} -DCMAKE_CUDA_ARCHITECTURES=90 \\\n && cmake --build build --target install -j \\\n && cd /sgl-workspace/DeepEP \\\n && NVSHMEM_DIR=${NVSHMEM_DIR} pip install .\n\n# Python tools\nRUN python3 -m pip install --no-cache-dir \\\n    datamodel_code_generator \\\n    mooncake_transfer_engine==0.3.4.post2 \\\n    pre-commit \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    uv \\\n    wheel \\\n    scikit-build-core\n\n# Install development tools and utilities\nRUN apt-get update && apt-get install -y \\\n    gdb \\\n    ninja-build \\\n    vim \\\n    tmux \\\n    htop \\\n    wget \\\n    curl \\\n    locales \\\n    lsof \\\n    git \\\n    git-lfs \\\n    zsh \\\n    tree \\\n    silversearcher-ag \\\n    cloc \\\n    unzip \\\n    pkg-config \\\n    libssl-dev \\\n    bear \\\n    ccache \\\n    less \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt-get clean\n\nRUN apt update -y \\\n    && apt install -y --no-install-recommends gnupg \\\n    && echo \"deb http://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64 /\" | tee /etc/apt/sources.list.d/nvidia-devtools.list \\\n    && apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub \\\n    && apt update -y \\\n    && apt install nsight-systems-cli -y\n\n# Set up locale\nRUN locale-gen en_US.UTF-8\nENV LANG en_US.UTF-8\nENV LANGUAGE en_US:en\nENV LC_ALL en_US.UTF-8\n\n# Install minimal Python packages\nRUN python3 -m pip install --no-cache-dir --break-system-packages \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    scikit_build_core \\\n    uv \\\n    pre-commit \\\n    pandas \\\n    matplotlib \\\n    tabulate\n\n# Install diff-so-fancy\nRUN curl -LSso /usr/local/bin/diff-so-fancy https://github.com/so-fancy/diff-so-fancy/releases/download/v1.4.4/diff-so-fancy \\\n    && chmod +x /usr/local/bin/diff-so-fancy\n\n# Install clang-format\nRUN curl -LSso /usr/local/bin/clang-format https://github.com/muttleyxd/clang-tools-static-binaries/releases/download/master-32d3ac78/clang-format-16_linux-amd64 \\\n    && chmod +x /usr/local/bin/clang-format\n\n# Install clangd\nRUN curl -L https://github.com/clangd/clangd/releases/download/18.1.3/clangd-linux-18.1.3.zip -o clangd.zip \\\n    && unzip clangd.zip \\\n    && cp -r clangd_18.1.3/bin/* /usr/local/bin/ \\\n    && cp -r clangd_18.1.3/lib/* /usr/local/lib/ \\\n    && rm -rf clangd_18.1.3 clangd.zip\n\n# Install CMake\nRUN wget https://github.com/Kitware/CMake/releases/download/v3.31.1/cmake-3.31.1-linux-x86_64.tar.gz \\\n    && tar -xzf cmake-3.31.1-linux-x86_64.tar.gz \\\n    && cp -r cmake-3.31.1-linux-x86_64/bin/* /usr/local/bin/ \\\n    && cp -r cmake-3.31.1-linux-x86_64/share/* /usr/local/share/ \\\n    && rm -rf cmake-3.31.1-linux-x86_64 cmake-3.31.1-linux-x86_64.tar.gz\n\n# Add yank script\nCOPY --chown=root:root <<-\"EOF\" /usr/local/bin/yank\n#!/bin/bash\nput() {\n  esc=$1\n  test -n \"$TMUX\" -o -z \"${TERM##screen*}\" && esc=\"\\033Ptmux;\\033$esc\\033\\\\\"\n  printf \"$esc\"\n}\nput \"\\033]52;c;!\\a\"\nbuf=$( cat \"$@\" )\nlen=$( printf %s \"$buf\" | wc -c ) max=74994\ntest $len -gt $max && echo \"$0: input is $(( len - max )) bytes too long\" >&2\nput \"\\033]52;c;$( printf %s \"$buf\" | head -c $max | base64 | tr -d '\\r\\n' )\\a\"\ntest -n \"$TMUX\" && tmux set-buffer \"$buf\" ||:\nEOF\n\nRUN chmod +x /usr/local/bin/yank\n\n# Install oh-my-zsh and plugins\nRUN sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" \"\" --unattended \\\n    && git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions \\\n    && git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\n# Configure Vim\nCOPY --chown=root:root <<-\"EOF\" /root/.vimrc\nfunction! Yank(text) abort\n  let escape = system('yank', a:text)\n  if v:shell_error\n    echoerr escape\n  else\n    call writefile([escape], '/dev/tty', 'b')\n  endif\nendfunction\n\nnoremap <silent> <Leader>y y:<C-U>call Yank(@0)<CR>\n\n\" automatically run yank(1) whenever yanking in Vim\nfunction! CopyYank() abort\n  call Yank(join(v:event.regcontents, \"\\n\"))\nendfunction\n\nautocmd TextYankPost * call CopyYank()\n\n\" Basic settings\nset number\nsyntax on\nset mouse=a\nfiletype indent on\n\n\" Indentation\nset autoindent nosmartindent\nset smarttab\nset expandtab\nset shiftwidth=4\nset softtabstop=4\n\n\" Visual guides\nset colorcolumn=120\nhighlight ColorColumn ctermbg=5\n\n\" Status line\nset laststatus=2\nset statusline=%<%f\\ %h%m%r%=%{\\\"[\\\".(&fenc==\\\"\\\"?&enc:&fenc).((exists(\\\"+bomb\\\")\\ &&\\ &bomb)?\\\",B\\\":\\\"\\\").\\\"]\\ \\\"}%k\\ %-14.(%l,%c%V%)\\ %P\n\n\" Backspace behavior\nset backspace=2\n\n\" Encoding\nset encoding=utf-8\nset fileencoding=utf-8\nEOF\n\n# Configure tmux\nCOPY --chown=root:root <<-\"EOF\" /root/.tmux.conf\n# Pane border styling\nset -g pane-border-style fg='#742727',bg=black\nset -g pane-active-border-style fg=red,bg=black\n\n# Status bar styling\nset -g status-style bg='#0C8A92',fg=black\n\n# Change prefix key to backtick\nset-option -g prefix `\nunbind C-b\nbind-key ` send-prefix\n\n# Split panes using - and = with current path\nunbind '\"'\nbind - splitw -v -c '#{pane_current_path}'\nunbind '%'\nbind = splitw -h -c '#{pane_current_path}'\n\n# Vi mode settings\nbind-key -T copy-mode-vi Y send-keys -X copy-pipe 'yank > #{pane_tty}'\nset-window-option -g mode-keys vi\n\n# Other settings\nset-option -g escape-time 0\nset-option -g base-index 1\nset-window-option -g mouse on\nEOF\n\n# Configure Git\nRUN git config --global core.editor \"vim\" \\\n    && git config --global core.whitespace \"fix,-indent-with-non-tab,trailing-space,cr-at-eol\" \\\n    && git config --global core.pager \"diff-so-fancy | less --tabs=4 -RFX\" \\\n    && git config --global color.ui true \\\n    && git config --global color.\"diff-highlight\".oldNormal \"red bold\" \\\n    && git config --global color.\"diff-highlight\".oldHighlight \"red bold 52\" \\\n    && git config --global color.\"diff-highlight\".newNormal \"green bold\" \\\n    && git config --global color.\"diff-highlight\".newHighlight \"green bold 22\" \\\n    && git config --global color.diff.meta \"11\" \\\n    && git config --global color.diff.frag \"magenta bold\" \\\n    && git config --global color.diff.commit \"yellow bold\" \\\n    && git config --global color.diff.old \"red bold\" \\\n    && git config --global color.diff.new \"green bold\" \\\n    && git config --global color.diff.whitespace \"red reverse\" \\\n    && git config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset - %s %Cgreen(%cr) %C(bold blue)<%an>%Creset%C(auto)%d%Creset' --abbrev-commit --\" \\\n    && git config --global http.sslVerify false \\\n    && git config --global pull.rebase true\n\n# Configure zsh\nCOPY --chown=root:root <<-\"EOF\" /root/.zshrc\nexport ZSH=\"/root/.oh-my-zsh\"\n\n# Theme\nZSH_THEME=\"robbyrussell\"\n\n# Plugins\nplugins=(\n    git\n    z\n    zsh-autosuggestions\n    zsh-syntax-highlighting\n)\n\nsource $ZSH/oh-my-zsh.sh\n\n# Aliases\nalias ll='ls -alF'\nalias la='ls -A'\nalias l='ls -CF'\nalias vi='vim'\n\n# Enhanced history\nHISTSIZE=10000\nSAVEHIST=10000\nsetopt HIST_IGNORE_ALL_DUPS\nsetopt HIST_FIND_NO_DUPS\nsetopt INC_APPEND_HISTORY\nEOF\n\nRUN set -euxo ; \\\n    curl --proto '=https' --tlsv1.2 -sSf https://just.systems/install.sh | bash -s -- --to /usr/local/bin\n\n# Set workspace directory\nWORKDIR /sgl-workspace/sglang\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.6.1\nFROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive \\\n    CUDA_HOME=/usr/local/cuda \\\n    GDRCOPY_HOME=/usr/src/gdrdrv-2.4.4/ \\\n    NVSHMEM_DIR=/sgl-workspace/nvshmem/install\n\n# Set timezone and install all packages\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n && apt-get update && apt-get install -y --no-install-recommends \\\n    tzdata \\\n    software-properties-common netcat-openbsd kmod unzip openssh-server \\\n    curl wget lsof zsh ccache tmux htop git-lfs tree \\\n    python3 python3-pip python3-dev libpython3-dev \\\n    build-essential cmake \\\n    libopenmpi-dev libnuma1 libnuma-dev \\\n    libibverbs-dev libibverbs1 libibumad3 \\\n    librdmacm1 libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnl-3-dev \\\n    ibverbs-providers infiniband-diags perftest \\\n    libgoogle-glog-dev libgtest-dev libjsoncpp-dev libunwind-dev \\\n    libboost-all-dev libssl-dev \\\n    libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc \\\n    pybind11-dev \\\n    libhiredis-dev libcurl4-openssl-dev \\\n    libczmq4 libczmq-dev \\\n    libfabric-dev \\\n    patchelf \\\n    nvidia-dkms-550 \\\n    devscripts debhelper fakeroot dkms check libsubunit0 libsubunit-dev \\\n && ln -sf /usr/bin/python3 /usr/bin/python \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# GDRCopy installation\nRUN mkdir -p /tmp/gdrcopy && cd /tmp \\\n && git clone https://github.com/NVIDIA/gdrcopy.git -b v2.4.4 \\\n && cd gdrcopy/packages \\\n && CUDA=/usr/local/cuda ./build-deb-packages.sh \\\n && dpkg -i gdrdrv-dkms_*.deb libgdrapi_*.deb gdrcopy-tests_*.deb gdrcopy_*.deb \\\n && cd / && rm -rf /tmp/gdrcopy\n\n# Fix DeepEP IBGDA symlink\nRUN ln -sf /usr/lib/x86_64-linux-gnu/libmlx5.so.1 /usr/lib/x86_64-linux-gnu/libmlx5.so\n\n# Clone and install SGLang\nWORKDIR /sgl-workspace\nRUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel html5lib six \\\n && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n && cd sglang \\\n && case \"$CUDA_VERSION\" in \\\n      12.6.1) CUINDEX=126 ;; \\\n      12.8.1) CUINDEX=128 ;; \\\n      *) echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1 ;; \\\n    esac \\\n && python3 -m pip install --no-cache-dir -e \"python[${BUILD_TYPE}]\" --extra-index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n      python3 -m pip install --no-cache-dir nvidia-nccl-cu12==2.27.5 --force-reinstall --no-deps ; \\\n      python3 -m pip install --no-cache-dir https://github.com/sgl-project/whl/releases/download/v0.2.5/sgl_kernel-0.2.5+cu128-cp39-abi3-manylinux2014_x86_64.whl --force-reinstall --no-deps ; \\\n    fi\n\n# Build and install NVSHMEM + DeepEP\nRUN wget https://developer.download.nvidia.com/compute/redist/nvshmem/3.2.5/source/nvshmem_src_3.2.5-1.txz \\\n && git clone https://github.com/deepseek-ai/DeepEP.git \\\n && tar -xf nvshmem_src_3.2.5-1.txz && mv nvshmem_src nvshmem \\\n && cd nvshmem \\\n && git apply /sgl-workspace/DeepEP/third-party/nvshmem.patch \\\n && sed -i '1i#include <unistd.h>' examples/moe_shuffle.cu \\\n && rm -f /sgl-workspace/nvshmem_src_3.2.5-1.txz \\\n && NVSHMEM_SHMEM_SUPPORT=0 \\\n    NVSHMEM_UCX_SUPPORT=0 \\\n    NVSHMEM_USE_NCCL=0 \\\n    NVSHMEM_MPI_SUPPORT=0 \\\n    NVSHMEM_IBGDA_SUPPORT=1 \\\n    NVSHMEM_PMIX_SUPPORT=0 \\\n    NVSHMEM_TIMEOUT_DEVICE_POLLING=0 \\\n    NVSHMEM_USE_GDRCOPY=1 \\\n    cmake -S . -B build/ -DCMAKE_INSTALL_PREFIX=${NVSHMEM_DIR} -DCMAKE_CUDA_ARCHITECTURES=90 \\\n && cmake --build build --target install -j \\\n && cd /sgl-workspace/DeepEP \\\n && NVSHMEM_DIR=${NVSHMEM_DIR} pip install .\n\n# Python tools\nRUN python3 -m pip install --no-cache-dir \\\n    datamodel_code_generator \\\n    mooncake_transfer_engine==0.3.4.post2 \\\n    pre-commit \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    uv \\\n    wheel \\\n    scikit-build-core\n\n# Install development tools and utilities\nRUN apt-get update && apt-get install -y \\\n    gdb \\\n    ninja-build \\\n    vim \\\n    tmux \\\n    htop \\\n    wget \\\n    curl \\\n    locales \\\n    lsof \\\n    git \\\n    git-lfs \\\n    zsh \\\n    tree \\\n    silversearcher-ag \\\n    cloc \\\n    unzip \\\n    pkg-config \\\n    libssl-dev \\\n    bear \\\n    ccache \\\n    less \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt-get clean\n\nRUN apt update -y \\\n    && apt install -y --no-install-recommends gnupg \\\n    && echo \"deb http://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64 /\" | tee /etc/apt/sources.list.d/nvidia-devtools.list \\\n    && apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub \\\n    && apt update -y \\\n    && apt install nsight-systems-cli -y\n\n# Set up locale\nRUN locale-gen en_US.UTF-8\nENV LANG en_US.UTF-8\nENV LANGUAGE en_US:en\nENV LC_ALL en_US.UTF-8\n\n# Install minimal Python packages\nRUN python3 -m pip install --no-cache-dir --break-system-packages \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    scikit_build_core \\\n    uv \\\n    pre-commit \\\n    pandas \\\n    matplotlib \\\n    tabulate\n\n# Install diff-so-fancy\nRUN curl -LSso /usr/local/bin/diff-so-fancy https://github.com/so-fancy/diff-so-fancy/releases/download/v1.4.4/diff-so-fancy \\\n    && chmod +x /usr/local/bin/diff-so-fancy\n\n# Install clang-format\nRUN curl -LSso /usr/local/bin/clang-format https://github.com/muttleyxd/clang-tools-static-binaries/releases/download/master-32d3ac78/clang-format-16_linux-amd64 \\\n    && chmod +x /usr/local/bin/clang-format\n\n# Install clangd\nRUN curl -L https://github.com/clangd/clangd/releases/download/18.1.3/clangd-linux-18.1.3.zip -o clangd.zip \\\n    && unzip clangd.zip \\\n    && cp -r clangd_18.1.3/bin/* /usr/local/bin/ \\\n    && cp -r clangd_18.1.3/lib/* /usr/local/lib/ \\\n    && rm -rf clangd_18.1.3 clangd.zip\n\n# Install CMake\nRUN wget https://github.com/Kitware/CMake/releases/download/v3.31.1/cmake-3.31.1-linux-x86_64.tar.gz \\\n    && tar -xzf cmake-3.31.1-linux-x86_64.tar.gz \\\n    && cp -r cmake-3.31.1-linux-x86_64/bin/* /usr/local/bin/ \\\n    && cp -r cmake-3.31.1-linux-x86_64/share/* /usr/local/share/ \\\n    && rm -rf cmake-3.31.1-linux-x86_64 cmake-3.31.1-linux-x86_64.tar.gz\n\n# Add yank script\nCOPY --chown=root:root <<-\"EOF\" /usr/local/bin/yank\n#!/bin/bash\nput() {\n  esc=$1\n  test -n \"$TMUX\" -o -z \"${TERM##screen*}\" && esc=\"\\033Ptmux;\\033$esc\\033\\\\\"\n  printf \"$esc\"\n}\nput \"\\033]52;c;!\\a\"\nbuf=$( cat \"$@\" )\nlen=$( printf %s \"$buf\" | wc -c ) max=74994\ntest $len -gt $max && echo \"$0: input is $(( len - max )) bytes too long\" >&2\nput \"\\033]52;c;$( printf %s \"$buf\" | head -c $max | base64 | tr -d '\\r\\n' )\\a\"\ntest -n \"$TMUX\" && tmux set-buffer \"$buf\" ||:\nEOF\n\nRUN chmod +x /usr/local/bin/yank\n\n# Install oh-my-zsh and plugins\nRUN sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" \"\" --unattended \\\n    && git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions \\\n    && git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\n# Configure Vim\nCOPY --chown=root:root <<-\"EOF\" /root/.vimrc\nfunction! Yank(text) abort\n  let escape = system('yank', a:text)\n  if v:shell_error\n    echoerr escape\n  else\n    call writefile([escape], '/dev/tty', 'b')\n  endif\nendfunction\n\nnoremap <silent> <Leader>y y:<C-U>call Yank(@0)<CR>\n\n\" automatically run yank(1) whenever yanking in Vim\nfunction! CopyYank() abort\n  call Yank(join(v:event.regcontents, \"\\n\"))\nendfunction\n\nautocmd TextYankPost * call CopyYank()\n\n\" Basic settings\nset number\nsyntax on\nset mouse=a\nfiletype indent on\n\n\" Indentation\nset autoindent nosmartindent\nset smarttab\nset expandtab\nset shiftwidth=4\nset softtabstop=4\n\n\" Visual guides\nset colorcolumn=120\nhighlight ColorColumn ctermbg=5\n\n\" Status line\nset laststatus=2\nset statusline=%<%f\\ %h%m%r%=%{\\\"[\\\".(&fenc==\\\"\\\"?&enc:&fenc).((exists(\\\"+bomb\\\")\\ &&\\ &bomb)?\\\",B\\\":\\\"\\\").\\\"]\\ \\\"}%k\\ %-14.(%l,%c%V%)\\ %P\n\n\" Backspace behavior\nset backspace=2\n\n\" Encoding\nset encoding=utf-8\nset fileencoding=utf-8\nEOF\n\n# Configure tmux\nCOPY --chown=root:root <<-\"EOF\" /root/.tmux.conf\n# Pane border styling\nset -g pane-border-style fg='#742727',bg=black\nset -g pane-active-border-style fg=red,bg=black\n\n# Status bar styling\nset -g status-style bg='#0C8A92',fg=black\n\n# Change prefix key to backtick\nset-option -g prefix `\nunbind C-b\nbind-key ` send-prefix\n\n# Split panes using - and = with current path\nunbind '\"'\nbind - splitw -v -c '#{pane_current_path}'\nunbind '%'\nbind = splitw -h -c '#{pane_current_path}'\n\n# Vi mode settings\nbind-key -T copy-mode-vi Y send-keys -X copy-pipe 'yank > #{pane_tty}'\nset-window-option -g mode-keys vi\n\n# Other settings\nset-option -g escape-time 0\nset-option -g base-index 1\nset-window-option -g mouse on\nEOF\n\n# Configure Git\nRUN git config --global core.editor \"vim\" \\\n    && git config --global core.whitespace \"fix,-indent-with-non-tab,trailing-space,cr-at-eol\" \\\n    && git config --global core.pager \"diff-so-fancy | less --tabs=4 -RFX\" \\\n    && git config --global color.ui true \\\n    && git config --global color.\"diff-highlight\".oldNormal \"red bold\" \\\n    && git config --global color.\"diff-highlight\".oldHighlight \"red bold 52\" \\\n    && git config --global color.\"diff-highlight\".newNormal \"green bold\" \\\n    && git config --global color.\"diff-highlight\".newHighlight \"green bold 22\" \\\n    && git config --global color.diff.meta \"11\" \\\n    && git config --global color.diff.frag \"magenta bold\" \\\n    && git config --global color.diff.commit \"yellow bold\" \\\n    && git config --global color.diff.old \"red bold\" \\\n    && git config --global color.diff.new \"green bold\" \\\n    && git config --global color.diff.whitespace \"red reverse\" \\\n    && git config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset - %s %Cgreen(%cr) %C(bold blue)<%an>%Creset%C(auto)%d%Creset' --abbrev-commit --\" \\\n    && git config --global http.sslVerify false \\\n    && git config --global pull.rebase true\n\n# Configure zsh\nCOPY --chown=root:root <<-\"EOF\" /root/.zshrc\nexport ZSH=\"/root/.oh-my-zsh\"\n\n# Theme\nZSH_THEME=\"robbyrussell\"\n\n# Plugins\nplugins=(\n    git\n    z\n    zsh-autosuggestions\n    zsh-syntax-highlighting\n)\n\nsource $ZSH/oh-my-zsh.sh\n\n# Aliases\nalias ll='ls -alF'\nalias la='ls -A'\nalias l='ls -CF'\nalias vi='vim'\n\n# Enhanced history\nHISTSIZE=10000\nSAVEHIST=10000\nsetopt HIST_IGNORE_ALL_DUPS\nsetopt HIST_FIND_NO_DUPS\nsetopt INC_APPEND_HISTORY\nEOF\n\nRUN set -euxo ; \\\n    curl --proto '=https' --tlsv1.2 -sSf https://just.systems/install.sh | bash -s -- --to /usr/local/bin\n\n# Set workspace directory\nWORKDIR /sgl-workspace/sglang\n"}
{"commit_hash": "8f8f96a6217ea737c94e7429e480196319594459", "commit_short": "8f8f96a6217e", "commit_subject": "Fix the perf regression due to additional_stop_token_ids (#1773)", "pr_url": "https://github.com/sgl-project/sglang/pull/1773", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Server failed to start", "error_date": "2026-01-06", "parent_commit": "05b3bf5e8e4751cf51510198ae2e864c4b11ac2f", "human_only_success": false, "human_only_date": "2026-01-06", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "9183c23eca51bf76159e81dfd6edf5770796c2d8", "commit_short": "9183c23eca51", "commit_subject": "Speed up `update_weights_from_tensor` (#2695)", "pr_url": "https://github.com/sgl-project/sglang/pull/2695", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "148254d4db8bf3bffee23710cd1acbd5711ebd1b", "human_throughput": 1567.2, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu121/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu124/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu118/torch2.4/flashinfer/; \\\n         else \\\n           echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n         fi; \\\n       else \\\n         if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu121/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu124/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu118/torch2.4/flashinfer/; \\\n         else \\\n           echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n         fi; \\\n       fi\n\nRUN python3 -m pip cache purge\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu121/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu124/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu118/torch2.4/flashinfer/; \\\n         else \\\n           echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n         fi; \\\n       else \\\n         if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu121/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu124/torch2.4/flashinfer/; \\\n         elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu118/torch2.4/flashinfer/; \\\n         else \\\n           echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n         fi; \\\n       fi\n\nRUN python3 -m pip cache purge\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "9216b10678a036a1797e19693b0445c889016687", "commit_short": "9216b10678a0", "commit_subject": "Improve performance when running with full parallel (#394)", "pr_url": "https://github.com/sgl-project/sglang/pull/394", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "da19434c2f3cbe4f367f84993da0bcbd84efb6ba", "human_throughput": 1562.4, "has_dockerfile": false, "dockerfile_path": null, "dockerfile_content": null, "parent_has_dockerfile": false, "parent_dockerfile_path": null, "parent_dockerfile_content": null}
{"commit_hash": "9c064bf78af8558dbc50fbd809f65dcafd6fd965", "commit_short": "9c064bf78af8", "commit_subject": "[LoRA, Performance] Speedup multi-LoRA serving - Step 1 (#1587)", "pr_url": "https://github.com/sgl-project/sglang/pull/1587", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Docker: flashinfer/torch ABI mismatch - rebuild image with matching versions", "error_date": "2026-01-04", "parent_commit": "58d1082e392cabbf26c404cb7ec18e4cb51b99e9", "human_only_success": true, "human_only_date": "2026-01-06", "human_throughput": 1403.0, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "9c088829ee2a28263f36d0814fde448c6090b5bc", "commit_short": "9c088829ee2a", "commit_subject": "Revert \"Use device_id in dist init to reduce NCCL communicator warmup & creation overhead\" (#5786)", "pr_url": "https://github.com/sgl-project/sglang/pull/5786", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "005aad32ad45ce27d73fd39aa1f7e9ba5d8ebb8f", "human_throughput": 1568.2, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.5.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.5.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "9c745d078e29e153a64300bd07636c7c9c1c42d5", "commit_short": "9c745d078e29", "commit_subject": "[Performance] Update xgrammar-related constrained decoding (#2056)", "pr_url": "https://github.com/sgl-project/sglang/pull/2056", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Server failed to start", "error_date": "2026-01-06", "parent_commit": "ebaa2f31996e80e4128b832d70f29f288b59944e", "human_only_success": false, "human_only_date": "2026-01-06", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "a191a0e47c2f0b0c8aed28080b9cb78624365e92", "commit_short": "a191a0e47c2f", "commit_subject": "Improve performance of two batch overlap in some imbalanced cases (#6593)", "pr_url": "https://github.com/sgl-project/sglang/pull/6593", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "8c7279c24e535681478188967b3007916b87b3d0", "human_throughput": 1593.4, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "a37e1247c183cff86a18f2ed1a075e40704b1c5e", "commit_short": "a37e1247c183", "commit_subject": "[Multimodal][Perf] Use `pybase64` instead of `base64` (#7724)", "pr_url": "https://github.com/sgl-project/sglang/pull/7724", "models": ["Qwen/Qwen2.5-VL-7B-Instruct"], "perf_command": "python3 -m sglang.bench_serving --backend sglang --model Qwen/Qwen2.5-VL-7B-Instruct --dataset-name mmmu --request-rate 10 --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Server failed to start", "error_date": "2026-01-06", "parent_commit": "136c6e0431c2067c3a2a98ad2c77fc89a9cb98e7", "human_only_success": false, "human_only_date": "2026-01-06", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.6.1\nFROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive \\\n    CUDA_HOME=/usr/local/cuda \\\n    GDRCOPY_HOME=/usr/src/gdrdrv-2.4.4/ \\\n    NVSHMEM_DIR=/sgl-workspace/nvshmem/install\n\n# Set timezone and install all packages\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n && apt-get update && apt-get install -y --no-install-recommends \\\n    tzdata \\\n    software-properties-common netcat-openbsd kmod unzip openssh-server \\\n    curl wget lsof zsh ccache tmux htop git-lfs tree \\\n    python3 python3-pip python3-dev libpython3-dev \\\n    build-essential cmake \\\n    libopenmpi-dev libnuma1 libnuma-dev \\\n    libibverbs-dev libibverbs1 libibumad3 \\\n    librdmacm1 libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnl-3-dev \\\n    ibverbs-providers infiniband-diags perftest \\\n    libgoogle-glog-dev libgtest-dev libjsoncpp-dev libunwind-dev \\\n    libboost-all-dev libssl-dev \\\n    libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc \\\n    pybind11-dev \\\n    libhiredis-dev libcurl4-openssl-dev \\\n    libczmq4 libczmq-dev \\\n    libfabric-dev \\\n    patchelf \\\n    nvidia-dkms-550 \\\n    devscripts debhelper fakeroot dkms check libsubunit0 libsubunit-dev \\\n && ln -sf /usr/bin/python3 /usr/bin/python \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# GDRCopy installation\nRUN mkdir -p /tmp/gdrcopy && cd /tmp \\\n && git clone https://github.com/NVIDIA/gdrcopy.git -b v2.4.4 \\\n && cd gdrcopy/packages \\\n && CUDA=/usr/local/cuda ./build-deb-packages.sh \\\n && dpkg -i gdrdrv-dkms_*.deb libgdrapi_*.deb gdrcopy-tests_*.deb gdrcopy_*.deb \\\n && cd / && rm -rf /tmp/gdrcopy\n\n# Fix DeepEP IBGDA symlink\nRUN ln -sf /usr/lib/x86_64-linux-gnu/libmlx5.so.1 /usr/lib/x86_64-linux-gnu/libmlx5.so\n\n# Clone and install SGLang\nWORKDIR /sgl-workspace\nRUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel html5lib six \\\n && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n && cd sglang \\\n && case \"$CUDA_VERSION\" in \\\n      12.6.1) CUINDEX=126 ;; \\\n      12.8.1) CUINDEX=128 ;; \\\n      *) echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1 ;; \\\n    esac \\\n && python3 -m pip install --no-cache-dir -e \"python[${BUILD_TYPE}]\" --extra-index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n      python3 -m pip install --no-cache-dir nvidia-nccl-cu12==2.27.5 --force-reinstall --no-deps ; \\\n      python3 -m pip install --no-cache-dir https://github.com/sgl-project/whl/releases/download/v0.2.4/sgl_kernel-0.2.4+cu128-cp39-abi3-manylinux2014_x86_64.whl --force-reinstall --no-deps ; \\\n    fi\n\n# Build and install NVSHMEM + DeepEP\nRUN wget https://developer.download.nvidia.com/compute/redist/nvshmem/3.2.5/source/nvshmem_src_3.2.5-1.txz \\\n && git clone https://github.com/deepseek-ai/DeepEP.git \\\n && tar -xf nvshmem_src_3.2.5-1.txz && mv nvshmem_src nvshmem \\\n && cd nvshmem \\\n && git apply /sgl-workspace/DeepEP/third-party/nvshmem.patch \\\n && sed -i '1i#include <unistd.h>' examples/moe_shuffle.cu \\\n && rm -f /sgl-workspace/nvshmem_src_3.2.5-1.txz \\\n && NVSHMEM_SHMEM_SUPPORT=0 \\\n    NVSHMEM_UCX_SUPPORT=0 \\\n    NVSHMEM_USE_NCCL=0 \\\n    NVSHMEM_MPI_SUPPORT=0 \\\n    NVSHMEM_IBGDA_SUPPORT=1 \\\n    NVSHMEM_PMIX_SUPPORT=0 \\\n    NVSHMEM_TIMEOUT_DEVICE_POLLING=0 \\\n    NVSHMEM_USE_GDRCOPY=1 \\\n    cmake -S . -B build/ -DCMAKE_INSTALL_PREFIX=${NVSHMEM_DIR} -DCMAKE_CUDA_ARCHITECTURES=90 \\\n && cmake --build build --target install -j \\\n && cd /sgl-workspace/DeepEP \\\n && NVSHMEM_DIR=${NVSHMEM_DIR} pip install .\n\n# Python tools\nRUN python3 -m pip install --no-cache-dir \\\n    datamodel_code_generator \\\n    mooncake_transfer_engine==0.3.4.post2 \\\n    pre-commit \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    uv \\\n    wheel \\\n    scikit-build-core\n\n# Install development tools and utilities\nRUN apt-get update && apt-get install -y \\\n    gdb \\\n    ninja-build \\\n    vim \\\n    tmux \\\n    htop \\\n    wget \\\n    curl \\\n    locales \\\n    lsof \\\n    git \\\n    git-lfs \\\n    zsh \\\n    tree \\\n    silversearcher-ag \\\n    cloc \\\n    unzip \\\n    pkg-config \\\n    libssl-dev \\\n    bear \\\n    ccache \\\n    less \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt-get clean\n\nRUN apt update -y \\\n    && apt install -y --no-install-recommends gnupg \\\n    && echo \"deb http://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64 /\" | tee /etc/apt/sources.list.d/nvidia-devtools.list \\\n    && apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub \\\n    && apt update -y \\\n    && apt install nsight-systems-cli -y\n\n# Set up locale\nRUN locale-gen en_US.UTF-8\nENV LANG en_US.UTF-8\nENV LANGUAGE en_US:en\nENV LC_ALL en_US.UTF-8\n\n# Install minimal Python packages\nRUN python3 -m pip install --no-cache-dir --break-system-packages \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    scikit_build_core \\\n    uv \\\n    pre-commit \\\n    pandas \\\n    matplotlib \\\n    tabulate\n\n# Install diff-so-fancy\nRUN curl -LSso /usr/local/bin/diff-so-fancy https://github.com/so-fancy/diff-so-fancy/releases/download/v1.4.4/diff-so-fancy \\\n    && chmod +x /usr/local/bin/diff-so-fancy\n\n# Install clang-format\nRUN curl -LSso /usr/local/bin/clang-format https://github.com/muttleyxd/clang-tools-static-binaries/releases/download/master-32d3ac78/clang-format-16_linux-amd64 \\\n    && chmod +x /usr/local/bin/clang-format\n\n# Install clangd\nRUN curl -L https://github.com/clangd/clangd/releases/download/18.1.3/clangd-linux-18.1.3.zip -o clangd.zip \\\n    && unzip clangd.zip \\\n    && cp -r clangd_18.1.3/bin/* /usr/local/bin/ \\\n    && cp -r clangd_18.1.3/lib/* /usr/local/lib/ \\\n    && rm -rf clangd_18.1.3 clangd.zip\n\n# Install CMake\nRUN wget https://github.com/Kitware/CMake/releases/download/v3.31.1/cmake-3.31.1-linux-x86_64.tar.gz \\\n    && tar -xzf cmake-3.31.1-linux-x86_64.tar.gz \\\n    && cp -r cmake-3.31.1-linux-x86_64/bin/* /usr/local/bin/ \\\n    && cp -r cmake-3.31.1-linux-x86_64/share/* /usr/local/share/ \\\n    && rm -rf cmake-3.31.1-linux-x86_64 cmake-3.31.1-linux-x86_64.tar.gz\n\n# Add yank script\nCOPY --chown=root:root <<-\"EOF\" /usr/local/bin/yank\n#!/bin/bash\nput() {\n  esc=$1\n  test -n \"$TMUX\" -o -z \"${TERM##screen*}\" && esc=\"\\033Ptmux;\\033$esc\\033\\\\\"\n  printf \"$esc\"\n}\nput \"\\033]52;c;!\\a\"\nbuf=$( cat \"$@\" )\nlen=$( printf %s \"$buf\" | wc -c ) max=74994\ntest $len -gt $max && echo \"$0: input is $(( len - max )) bytes too long\" >&2\nput \"\\033]52;c;$( printf %s \"$buf\" | head -c $max | base64 | tr -d '\\r\\n' )\\a\"\ntest -n \"$TMUX\" && tmux set-buffer \"$buf\" ||:\nEOF\n\nRUN chmod +x /usr/local/bin/yank\n\n# Install oh-my-zsh and plugins\nRUN sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" \"\" --unattended \\\n    && git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions \\\n    && git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\n# Configure Vim\nCOPY --chown=root:root <<-\"EOF\" /root/.vimrc\nfunction! Yank(text) abort\n  let escape = system('yank', a:text)\n  if v:shell_error\n    echoerr escape\n  else\n    call writefile([escape], '/dev/tty', 'b')\n  endif\nendfunction\n\nnoremap <silent> <Leader>y y:<C-U>call Yank(@0)<CR>\n\n\" automatically run yank(1) whenever yanking in Vim\nfunction! CopyYank() abort\n  call Yank(join(v:event.regcontents, \"\\n\"))\nendfunction\n\nautocmd TextYankPost * call CopyYank()\n\n\" Basic settings\nset number\nsyntax on\nset mouse=a\nfiletype indent on\n\n\" Indentation\nset autoindent nosmartindent\nset smarttab\nset expandtab\nset shiftwidth=4\nset softtabstop=4\n\n\" Visual guides\nset colorcolumn=120\nhighlight ColorColumn ctermbg=5\n\n\" Status line\nset laststatus=2\nset statusline=%<%f\\ %h%m%r%=%{\\\"[\\\".(&fenc==\\\"\\\"?&enc:&fenc).((exists(\\\"+bomb\\\")\\ &&\\ &bomb)?\\\",B\\\":\\\"\\\").\\\"]\\ \\\"}%k\\ %-14.(%l,%c%V%)\\ %P\n\n\" Backspace behavior\nset backspace=2\n\n\" Encoding\nset encoding=utf-8\nset fileencoding=utf-8\nEOF\n\n# Configure tmux\nCOPY --chown=root:root <<-\"EOF\" /root/.tmux.conf\n# Pane border styling\nset -g pane-border-style fg='#742727',bg=black\nset -g pane-active-border-style fg=red,bg=black\n\n# Status bar styling\nset -g status-style bg='#0C8A92',fg=black\n\n# Change prefix key to backtick\nset-option -g prefix `\nunbind C-b\nbind-key ` send-prefix\n\n# Split panes using - and = with current path\nunbind '\"'\nbind - splitw -v -c '#{pane_current_path}'\nunbind '%'\nbind = splitw -h -c '#{pane_current_path}'\n\n# Vi mode settings\nbind-key -T copy-mode-vi Y send-keys -X copy-pipe 'yank > #{pane_tty}'\nset-window-option -g mode-keys vi\n\n# Other settings\nset-option -g escape-time 0\nset-option -g base-index 1\nset-window-option -g mouse on\nEOF\n\n# Configure Git\nRUN git config --global core.editor \"vim\" \\\n    && git config --global core.whitespace \"fix,-indent-with-non-tab,trailing-space,cr-at-eol\" \\\n    && git config --global core.pager \"diff-so-fancy | less --tabs=4 -RFX\" \\\n    && git config --global color.ui true \\\n    && git config --global color.\"diff-highlight\".oldNormal \"red bold\" \\\n    && git config --global color.\"diff-highlight\".oldHighlight \"red bold 52\" \\\n    && git config --global color.\"diff-highlight\".newNormal \"green bold\" \\\n    && git config --global color.\"diff-highlight\".newHighlight \"green bold 22\" \\\n    && git config --global color.diff.meta \"11\" \\\n    && git config --global color.diff.frag \"magenta bold\" \\\n    && git config --global color.diff.commit \"yellow bold\" \\\n    && git config --global color.diff.old \"red bold\" \\\n    && git config --global color.diff.new \"green bold\" \\\n    && git config --global color.diff.whitespace \"red reverse\" \\\n    && git config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset - %s %Cgreen(%cr) %C(bold blue)<%an>%Creset%C(auto)%d%Creset' --abbrev-commit --\" \\\n    && git config --global http.sslVerify false \\\n    && git config --global pull.rebase true\n\n# Configure zsh\nCOPY --chown=root:root <<-\"EOF\" /root/.zshrc\nexport ZSH=\"/root/.oh-my-zsh\"\n\n# Theme\nZSH_THEME=\"robbyrussell\"\n\n# Plugins\nplugins=(\n    git\n    z\n    zsh-autosuggestions\n    zsh-syntax-highlighting\n)\n\nsource $ZSH/oh-my-zsh.sh\n\n# Aliases\nalias ll='ls -alF'\nalias la='ls -A'\nalias l='ls -CF'\nalias vi='vim'\n\n# Enhanced history\nHISTSIZE=10000\nSAVEHIST=10000\nsetopt HIST_IGNORE_ALL_DUPS\nsetopt HIST_FIND_NO_DUPS\nsetopt INC_APPEND_HISTORY\nEOF\n\nRUN set -euxo ; \\\n    curl --proto '=https' --tlsv1.2 -sSf https://just.systems/install.sh | bash -s -- --to /usr/local/bin\n\n# Set workspace directory\nWORKDIR /sgl-workspace/sglang\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.6.1\nFROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive \\\n    CUDA_HOME=/usr/local/cuda \\\n    GDRCOPY_HOME=/usr/src/gdrdrv-2.4.4/ \\\n    NVSHMEM_DIR=/sgl-workspace/nvshmem/install\n\n# Set timezone and install all packages\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n && apt-get update && apt-get install -y --no-install-recommends \\\n    tzdata \\\n    software-properties-common netcat-openbsd kmod unzip openssh-server \\\n    curl wget lsof zsh ccache tmux htop git-lfs tree \\\n    python3 python3-pip python3-dev libpython3-dev \\\n    build-essential cmake \\\n    libopenmpi-dev libnuma1 libnuma-dev \\\n    libibverbs-dev libibverbs1 libibumad3 \\\n    librdmacm1 libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnl-3-dev \\\n    ibverbs-providers infiniband-diags perftest \\\n    libgoogle-glog-dev libgtest-dev libjsoncpp-dev libunwind-dev \\\n    libboost-all-dev libssl-dev \\\n    libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc \\\n    pybind11-dev \\\n    libhiredis-dev libcurl4-openssl-dev \\\n    libczmq4 libczmq-dev \\\n    libfabric-dev \\\n    patchelf \\\n    nvidia-dkms-550 \\\n    devscripts debhelper fakeroot dkms check libsubunit0 libsubunit-dev \\\n && ln -sf /usr/bin/python3 /usr/bin/python \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# GDRCopy installation\nRUN mkdir -p /tmp/gdrcopy && cd /tmp \\\n && git clone https://github.com/NVIDIA/gdrcopy.git -b v2.4.4 \\\n && cd gdrcopy/packages \\\n && CUDA=/usr/local/cuda ./build-deb-packages.sh \\\n && dpkg -i gdrdrv-dkms_*.deb libgdrapi_*.deb gdrcopy-tests_*.deb gdrcopy_*.deb \\\n && cd / && rm -rf /tmp/gdrcopy\n\n# Fix DeepEP IBGDA symlink\nRUN ln -sf /usr/lib/x86_64-linux-gnu/libmlx5.so.1 /usr/lib/x86_64-linux-gnu/libmlx5.so\n\n# Clone and install SGLang\nWORKDIR /sgl-workspace\nRUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel html5lib six \\\n && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n && cd sglang \\\n && case \"$CUDA_VERSION\" in \\\n      12.6.1) CUINDEX=126 ;; \\\n      12.8.1) CUINDEX=128 ;; \\\n      *) echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1 ;; \\\n    esac \\\n && python3 -m pip install --no-cache-dir -e \"python[${BUILD_TYPE}]\" --extra-index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n      python3 -m pip install --no-cache-dir nvidia-nccl-cu12==2.27.5 --force-reinstall --no-deps ; \\\n      python3 -m pip install --no-cache-dir https://github.com/sgl-project/whl/releases/download/v0.2.4/sgl_kernel-0.2.4+cu128-cp39-abi3-manylinux2014_x86_64.whl --force-reinstall --no-deps ; \\\n    fi\n\n# Build and install NVSHMEM + DeepEP\nRUN wget https://developer.download.nvidia.com/compute/redist/nvshmem/3.2.5/source/nvshmem_src_3.2.5-1.txz \\\n && git clone https://github.com/deepseek-ai/DeepEP.git \\\n && tar -xf nvshmem_src_3.2.5-1.txz && mv nvshmem_src nvshmem \\\n && cd nvshmem \\\n && git apply /sgl-workspace/DeepEP/third-party/nvshmem.patch \\\n && sed -i '1i#include <unistd.h>' examples/moe_shuffle.cu \\\n && rm -f /sgl-workspace/nvshmem_src_3.2.5-1.txz \\\n && NVSHMEM_SHMEM_SUPPORT=0 \\\n    NVSHMEM_UCX_SUPPORT=0 \\\n    NVSHMEM_USE_NCCL=0 \\\n    NVSHMEM_MPI_SUPPORT=0 \\\n    NVSHMEM_IBGDA_SUPPORT=1 \\\n    NVSHMEM_PMIX_SUPPORT=0 \\\n    NVSHMEM_TIMEOUT_DEVICE_POLLING=0 \\\n    NVSHMEM_USE_GDRCOPY=1 \\\n    cmake -S . -B build/ -DCMAKE_INSTALL_PREFIX=${NVSHMEM_DIR} -DCMAKE_CUDA_ARCHITECTURES=90 \\\n && cmake --build build --target install -j \\\n && cd /sgl-workspace/DeepEP \\\n && NVSHMEM_DIR=${NVSHMEM_DIR} pip install .\n\n# Python tools\nRUN python3 -m pip install --no-cache-dir \\\n    datamodel_code_generator \\\n    mooncake_transfer_engine==0.3.4.post2 \\\n    pre-commit \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    uv \\\n    wheel \\\n    scikit-build-core\n\n# Install development tools and utilities\nRUN apt-get update && apt-get install -y \\\n    gdb \\\n    ninja-build \\\n    vim \\\n    tmux \\\n    htop \\\n    wget \\\n    curl \\\n    locales \\\n    lsof \\\n    git \\\n    git-lfs \\\n    zsh \\\n    tree \\\n    silversearcher-ag \\\n    cloc \\\n    unzip \\\n    pkg-config \\\n    libssl-dev \\\n    bear \\\n    ccache \\\n    less \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt-get clean\n\nRUN apt update -y \\\n    && apt install -y --no-install-recommends gnupg \\\n    && echo \"deb http://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64 /\" | tee /etc/apt/sources.list.d/nvidia-devtools.list \\\n    && apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub \\\n    && apt update -y \\\n    && apt install nsight-systems-cli -y\n\n# Set up locale\nRUN locale-gen en_US.UTF-8\nENV LANG en_US.UTF-8\nENV LANGUAGE en_US:en\nENV LC_ALL en_US.UTF-8\n\n# Install minimal Python packages\nRUN python3 -m pip install --no-cache-dir --break-system-packages \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    scikit_build_core \\\n    uv \\\n    pre-commit \\\n    pandas \\\n    matplotlib \\\n    tabulate\n\n# Install diff-so-fancy\nRUN curl -LSso /usr/local/bin/diff-so-fancy https://github.com/so-fancy/diff-so-fancy/releases/download/v1.4.4/diff-so-fancy \\\n    && chmod +x /usr/local/bin/diff-so-fancy\n\n# Install clang-format\nRUN curl -LSso /usr/local/bin/clang-format https://github.com/muttleyxd/clang-tools-static-binaries/releases/download/master-32d3ac78/clang-format-16_linux-amd64 \\\n    && chmod +x /usr/local/bin/clang-format\n\n# Install clangd\nRUN curl -L https://github.com/clangd/clangd/releases/download/18.1.3/clangd-linux-18.1.3.zip -o clangd.zip \\\n    && unzip clangd.zip \\\n    && cp -r clangd_18.1.3/bin/* /usr/local/bin/ \\\n    && cp -r clangd_18.1.3/lib/* /usr/local/lib/ \\\n    && rm -rf clangd_18.1.3 clangd.zip\n\n# Install CMake\nRUN wget https://github.com/Kitware/CMake/releases/download/v3.31.1/cmake-3.31.1-linux-x86_64.tar.gz \\\n    && tar -xzf cmake-3.31.1-linux-x86_64.tar.gz \\\n    && cp -r cmake-3.31.1-linux-x86_64/bin/* /usr/local/bin/ \\\n    && cp -r cmake-3.31.1-linux-x86_64/share/* /usr/local/share/ \\\n    && rm -rf cmake-3.31.1-linux-x86_64 cmake-3.31.1-linux-x86_64.tar.gz\n\n# Add yank script\nCOPY --chown=root:root <<-\"EOF\" /usr/local/bin/yank\n#!/bin/bash\nput() {\n  esc=$1\n  test -n \"$TMUX\" -o -z \"${TERM##screen*}\" && esc=\"\\033Ptmux;\\033$esc\\033\\\\\"\n  printf \"$esc\"\n}\nput \"\\033]52;c;!\\a\"\nbuf=$( cat \"$@\" )\nlen=$( printf %s \"$buf\" | wc -c ) max=74994\ntest $len -gt $max && echo \"$0: input is $(( len - max )) bytes too long\" >&2\nput \"\\033]52;c;$( printf %s \"$buf\" | head -c $max | base64 | tr -d '\\r\\n' )\\a\"\ntest -n \"$TMUX\" && tmux set-buffer \"$buf\" ||:\nEOF\n\nRUN chmod +x /usr/local/bin/yank\n\n# Install oh-my-zsh and plugins\nRUN sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" \"\" --unattended \\\n    && git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions \\\n    && git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\n# Configure Vim\nCOPY --chown=root:root <<-\"EOF\" /root/.vimrc\nfunction! Yank(text) abort\n  let escape = system('yank', a:text)\n  if v:shell_error\n    echoerr escape\n  else\n    call writefile([escape], '/dev/tty', 'b')\n  endif\nendfunction\n\nnoremap <silent> <Leader>y y:<C-U>call Yank(@0)<CR>\n\n\" automatically run yank(1) whenever yanking in Vim\nfunction! CopyYank() abort\n  call Yank(join(v:event.regcontents, \"\\n\"))\nendfunction\n\nautocmd TextYankPost * call CopyYank()\n\n\" Basic settings\nset number\nsyntax on\nset mouse=a\nfiletype indent on\n\n\" Indentation\nset autoindent nosmartindent\nset smarttab\nset expandtab\nset shiftwidth=4\nset softtabstop=4\n\n\" Visual guides\nset colorcolumn=120\nhighlight ColorColumn ctermbg=5\n\n\" Status line\nset laststatus=2\nset statusline=%<%f\\ %h%m%r%=%{\\\"[\\\".(&fenc==\\\"\\\"?&enc:&fenc).((exists(\\\"+bomb\\\")\\ &&\\ &bomb)?\\\",B\\\":\\\"\\\").\\\"]\\ \\\"}%k\\ %-14.(%l,%c%V%)\\ %P\n\n\" Backspace behavior\nset backspace=2\n\n\" Encoding\nset encoding=utf-8\nset fileencoding=utf-8\nEOF\n\n# Configure tmux\nCOPY --chown=root:root <<-\"EOF\" /root/.tmux.conf\n# Pane border styling\nset -g pane-border-style fg='#742727',bg=black\nset -g pane-active-border-style fg=red,bg=black\n\n# Status bar styling\nset -g status-style bg='#0C8A92',fg=black\n\n# Change prefix key to backtick\nset-option -g prefix `\nunbind C-b\nbind-key ` send-prefix\n\n# Split panes using - and = with current path\nunbind '\"'\nbind - splitw -v -c '#{pane_current_path}'\nunbind '%'\nbind = splitw -h -c '#{pane_current_path}'\n\n# Vi mode settings\nbind-key -T copy-mode-vi Y send-keys -X copy-pipe 'yank > #{pane_tty}'\nset-window-option -g mode-keys vi\n\n# Other settings\nset-option -g escape-time 0\nset-option -g base-index 1\nset-window-option -g mouse on\nEOF\n\n# Configure Git\nRUN git config --global core.editor \"vim\" \\\n    && git config --global core.whitespace \"fix,-indent-with-non-tab,trailing-space,cr-at-eol\" \\\n    && git config --global core.pager \"diff-so-fancy | less --tabs=4 -RFX\" \\\n    && git config --global color.ui true \\\n    && git config --global color.\"diff-highlight\".oldNormal \"red bold\" \\\n    && git config --global color.\"diff-highlight\".oldHighlight \"red bold 52\" \\\n    && git config --global color.\"diff-highlight\".newNormal \"green bold\" \\\n    && git config --global color.\"diff-highlight\".newHighlight \"green bold 22\" \\\n    && git config --global color.diff.meta \"11\" \\\n    && git config --global color.diff.frag \"magenta bold\" \\\n    && git config --global color.diff.commit \"yellow bold\" \\\n    && git config --global color.diff.old \"red bold\" \\\n    && git config --global color.diff.new \"green bold\" \\\n    && git config --global color.diff.whitespace \"red reverse\" \\\n    && git config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset - %s %Cgreen(%cr) %C(bold blue)<%an>%Creset%C(auto)%d%Creset' --abbrev-commit --\" \\\n    && git config --global http.sslVerify false \\\n    && git config --global pull.rebase true\n\n# Configure zsh\nCOPY --chown=root:root <<-\"EOF\" /root/.zshrc\nexport ZSH=\"/root/.oh-my-zsh\"\n\n# Theme\nZSH_THEME=\"robbyrussell\"\n\n# Plugins\nplugins=(\n    git\n    z\n    zsh-autosuggestions\n    zsh-syntax-highlighting\n)\n\nsource $ZSH/oh-my-zsh.sh\n\n# Aliases\nalias ll='ls -alF'\nalias la='ls -A'\nalias l='ls -CF'\nalias vi='vim'\n\n# Enhanced history\nHISTSIZE=10000\nSAVEHIST=10000\nsetopt HIST_IGNORE_ALL_DUPS\nsetopt HIST_FIND_NO_DUPS\nsetopt INC_APPEND_HISTORY\nEOF\n\nRUN set -euxo ; \\\n    curl --proto '=https' --tlsv1.2 -sSf https://just.systems/install.sh | bash -s -- --to /usr/local/bin\n\n# Set workspace directory\nWORKDIR /sgl-workspace/sglang\n"}
{"commit_hash": "a99801e0750f41553fedd02e36f58d835c4d4bd6", "commit_short": "a99801e0750f", "commit_subject": "[Performance][PD Disaggregation] optimize TokenToKVPoolAllocator by sorting free pages (#8133)", "pr_url": "https://github.com/sgl-project/sglang/pull/8133", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "4c605235aa832f259e148dfbdce08d9e471b5099", "human_throughput": 1534.2, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.6.1\nFROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04\n\nARG BUILD_TYPE=all\nARG DEEPEP_COMMIT=b6ce310bb0b75079682d09bc2ebc063a074fbd58\nARG CMAKE_BUILD_PARALLEL_LEVEL=2\nENV DEBIAN_FRONTEND=noninteractive \\\n    CUDA_HOME=/usr/local/cuda \\\n    GDRCOPY_HOME=/usr/src/gdrdrv-2.4.4/ \\\n    NVSHMEM_DIR=/sgl-workspace/nvshmem/install\n\n# Set timezone and install all packages\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n && apt-get update && apt-get install -y --no-install-recommends \\\n    tzdata \\\n    software-properties-common netcat-openbsd kmod unzip openssh-server \\\n    curl wget lsof zsh ccache tmux htop git-lfs tree \\\n    python3 python3-pip python3-dev libpython3-dev python3-venv \\\n    build-essential cmake \\\n    libopenmpi-dev libnuma1 libnuma-dev \\\n    libibverbs-dev libibverbs1 libibumad3 \\\n    librdmacm1 libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnl-3-dev \\\n    ibverbs-providers infiniband-diags perftest \\\n    libgoogle-glog-dev libgtest-dev libjsoncpp-dev libunwind-dev \\\n    libboost-all-dev libssl-dev \\\n    libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc \\\n    pybind11-dev \\\n    libhiredis-dev libcurl4-openssl-dev \\\n    libczmq4 libczmq-dev \\\n    libfabric-dev \\\n    patchelf \\\n    nvidia-dkms-550 \\\n    devscripts debhelper fakeroot dkms check libsubunit0 libsubunit-dev \\\n && ln -sf /usr/bin/python3 /usr/bin/python \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# GDRCopy installation\nRUN mkdir -p /tmp/gdrcopy && cd /tmp \\\n && git clone https://github.com/NVIDIA/gdrcopy.git -b v2.4.4 \\\n && cd gdrcopy/packages \\\n && CUDA=/usr/local/cuda ./build-deb-packages.sh \\\n && dpkg -i gdrdrv-dkms_*.deb libgdrapi_*.deb gdrcopy-tests_*.deb gdrcopy_*.deb \\\n && cd / && rm -rf /tmp/gdrcopy\n\n# Fix DeepEP IBGDA symlink\nRUN ln -sf /usr/lib/x86_64-linux-gnu/libmlx5.so.1 /usr/lib/x86_64-linux-gnu/libmlx5.so\n\n# Clone and install SGLang\nWORKDIR /sgl-workspace\nRUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel html5lib six \\\n && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n && cd sglang \\\n && case \"$CUDA_VERSION\" in \\\n      12.6.1) CUINDEX=126 ;; \\\n      12.8.1) CUINDEX=128 ;; \\\n      *) echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1 ;; \\\n    esac \\\n && python3 -m pip install --no-cache-dir -e \"python[${BUILD_TYPE}]\" --extra-index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n      python3 -m pip install --no-cache-dir nvidia-nccl-cu12==2.27.6 --force-reinstall --no-deps ; \\\n      python3 -m pip install --no-cache-dir https://github.com/sgl-project/whl/releases/download/v0.2.7/sgl_kernel-0.2.7+cu128-cp39-abi3-manylinux2014_x86_64.whl --force-reinstall --no-deps ; \\\n    fi\n\n# Build and install NVSHMEM + DeepEP\nRUN wget https://developer.download.nvidia.com/compute/redist/nvshmem/3.3.9/source/nvshmem_src_cuda12-all-all-3.3.9.tar.gz \\\n && git clone https://github.com/deepseek-ai/DeepEP.git \\\n && cd DeepEP && git checkout ${DEEPEP_COMMIT} && cd .. \\\n && tar -xf nvshmem_src_cuda12-all-all-3.3.9.tar.gz && mv nvshmem_src nvshmem \\\n && cd nvshmem \\\n && rm -f /sgl-workspace/nvshmem_src_cuda12-all-all-3.3.9.tar.gz \\\n && NVSHMEM_SHMEM_SUPPORT=0 \\\n    NVSHMEM_UCX_SUPPORT=0 \\\n    NVSHMEM_USE_NCCL=0 \\\n    NVSHMEM_MPI_SUPPORT=0 \\\n    NVSHMEM_IBGDA_SUPPORT=1 \\\n    NVSHMEM_PMIX_SUPPORT=0 \\\n    NVSHMEM_TIMEOUT_DEVICE_POLLING=0 \\\n    NVSHMEM_USE_GDRCOPY=1 \\\n    cmake -S . -B build/ -DCMAKE_INSTALL_PREFIX=${NVSHMEM_DIR} -DCMAKE_CUDA_ARCHITECTURES=90 \\\n && cmake --build build --target install -j${CMAKE_BUILD_PARALLEL_LEVEL} \\\n && cd /sgl-workspace/DeepEP \\\n && NVSHMEM_DIR=${NVSHMEM_DIR} pip install .\n\n# Python tools\nRUN python3 -m pip install --no-cache-dir \\\n    datamodel_code_generator \\\n    mooncake_transfer_engine==0.3.4.post2 \\\n    pre-commit \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    uv \\\n    wheel \\\n    scikit-build-core\n\n# Install development tools and utilities\nRUN apt-get update && apt-get install -y \\\n    gdb \\\n    ninja-build \\\n    vim \\\n    tmux \\\n    htop \\\n    wget \\\n    curl \\\n    locales \\\n    lsof \\\n    git \\\n    git-lfs \\\n    zsh \\\n    tree \\\n    silversearcher-ag \\\n    cloc \\\n    unzip \\\n    pkg-config \\\n    libssl-dev \\\n    bear \\\n    ccache \\\n    less \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt-get clean\n\nRUN apt update -y \\\n    && apt install -y --no-install-recommends gnupg \\\n    && echo \"deb http://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64 /\" | tee /etc/apt/sources.list.d/nvidia-devtools.list \\\n    && apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub \\\n    && apt update -y \\\n    && apt install nsight-systems-cli -y\n\n# Set up locale\nRUN locale-gen en_US.UTF-8\nENV LANG en_US.UTF-8\nENV LANGUAGE en_US:en\nENV LC_ALL en_US.UTF-8\n\n# Install minimal Python packages\nRUN python3 -m pip install --no-cache-dir --break-system-packages \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    scikit_build_core \\\n    uv \\\n    pre-commit \\\n    pandas \\\n    matplotlib \\\n    tabulate\n\n# Install diff-so-fancy\nRUN curl -LSso /usr/local/bin/diff-so-fancy https://github.com/so-fancy/diff-so-fancy/releases/download/v1.4.4/diff-so-fancy \\\n    && chmod +x /usr/local/bin/diff-so-fancy\n\n# Install clang-format\nRUN curl -LSso /usr/local/bin/clang-format https://github.com/muttleyxd/clang-tools-static-binaries/releases/download/master-32d3ac78/clang-format-16_linux-amd64 \\\n    && chmod +x /usr/local/bin/clang-format\n\n# Install clangd\nRUN curl -L https://github.com/clangd/clangd/releases/download/18.1.3/clangd-linux-18.1.3.zip -o clangd.zip \\\n    && unzip clangd.zip \\\n    && cp -r clangd_18.1.3/bin/* /usr/local/bin/ \\\n    && cp -r clangd_18.1.3/lib/* /usr/local/lib/ \\\n    && rm -rf clangd_18.1.3 clangd.zip\n\n# Install CMake\nRUN wget https://github.com/Kitware/CMake/releases/download/v3.31.1/cmake-3.31.1-linux-x86_64.tar.gz \\\n    && tar -xzf cmake-3.31.1-linux-x86_64.tar.gz \\\n    && cp -r cmake-3.31.1-linux-x86_64/bin/* /usr/local/bin/ \\\n    && cp -r cmake-3.31.1-linux-x86_64/share/* /usr/local/share/ \\\n    && rm -rf cmake-3.31.1-linux-x86_64 cmake-3.31.1-linux-x86_64.tar.gz\n\n# Add yank script\nCOPY --chown=root:root <<-\"EOF\" /usr/local/bin/yank\n#!/bin/bash\nput() {\n  esc=$1\n  test -n \"$TMUX\" -o -z \"${TERM##screen*}\" && esc=\"\\033Ptmux;\\033$esc\\033\\\\\"\n  printf \"$esc\"\n}\nput \"\\033]52;c;!\\a\"\nbuf=$( cat \"$@\" )\nlen=$( printf %s \"$buf\" | wc -c ) max=74994\ntest $len -gt $max && echo \"$0: input is $(( len - max )) bytes too long\" >&2\nput \"\\033]52;c;$( printf %s \"$buf\" | head -c $max | base64 | tr -d '\\r\\n' )\\a\"\ntest -n \"$TMUX\" && tmux set-buffer \"$buf\" ||:\nEOF\n\nRUN chmod +x /usr/local/bin/yank\n\n# Install oh-my-zsh and plugins\nRUN sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" \"\" --unattended \\\n    && git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions \\\n    && git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\n# Configure Vim\nCOPY --chown=root:root <<-\"EOF\" /root/.vimrc\nfunction! Yank(text) abort\n  let escape = system('yank', a:text)\n  if v:shell_error\n    echoerr escape\n  else\n    call writefile([escape], '/dev/tty', 'b')\n  endif\nendfunction\n\nnoremap <silent> <Leader>y y:<C-U>call Yank(@0)<CR>\n\n\" automatically run yank(1) whenever yanking in Vim\nfunction! CopyYank() abort\n  call Yank(join(v:event.regcontents, \"\\n\"))\nendfunction\n\nautocmd TextYankPost * call CopyYank()\n\n\" Basic settings\nset number\nsyntax on\nset mouse=a\nfiletype indent on\n\n\" Indentation\nset autoindent nosmartindent\nset smarttab\nset expandtab\nset shiftwidth=4\nset softtabstop=4\n\n\" Visual guides\nset colorcolumn=120\nhighlight ColorColumn ctermbg=5\n\n\" Status line\nset laststatus=2\nset statusline=%<%f\\ %h%m%r%=%{\\\"[\\\".(&fenc==\\\"\\\"?&enc:&fenc).((exists(\\\"+bomb\\\")\\ &&\\ &bomb)?\\\",B\\\":\\\"\\\").\\\"]\\ \\\"}%k\\ %-14.(%l,%c%V%)\\ %P\n\n\" Backspace behavior\nset backspace=2\n\n\" Encoding\nset encoding=utf-8\nset fileencoding=utf-8\nEOF\n\n# Configure tmux\nCOPY --chown=root:root <<-\"EOF\" /root/.tmux.conf\n# Pane border styling\nset -g pane-border-style fg='#742727',bg=black\nset -g pane-active-border-style fg=red,bg=black\n\n# Status bar styling\nset -g status-style bg='#0C8A92',fg=black\n\n# Change prefix key to backtick\nset-option -g prefix `\nunbind C-b\nbind-key ` send-prefix\n\n# Split panes using - and = with current path\nunbind '\"'\nbind - splitw -v -c '#{pane_current_path}'\nunbind '%'\nbind = splitw -h -c '#{pane_current_path}'\n\n# Vi mode settings\nbind-key -T copy-mode-vi Y send-keys -X copy-pipe 'yank > #{pane_tty}'\nset-window-option -g mode-keys vi\n\n# Other settings\nset-option -g escape-time 0\nset-option -g base-index 1\nset-window-option -g mouse on\nEOF\n\n# Configure Git\nRUN git config --global core.editor \"vim\" \\\n    && git config --global core.whitespace \"fix,-indent-with-non-tab,trailing-space,cr-at-eol\" \\\n    && git config --global core.pager \"diff-so-fancy | less --tabs=4 -RFX\" \\\n    && git config --global color.ui true \\\n    && git config --global color.\"diff-highlight\".oldNormal \"red bold\" \\\n    && git config --global color.\"diff-highlight\".oldHighlight \"red bold 52\" \\\n    && git config --global color.\"diff-highlight\".newNormal \"green bold\" \\\n    && git config --global color.\"diff-highlight\".newHighlight \"green bold 22\" \\\n    && git config --global color.diff.meta \"11\" \\\n    && git config --global color.diff.frag \"magenta bold\" \\\n    && git config --global color.diff.commit \"yellow bold\" \\\n    && git config --global color.diff.old \"red bold\" \\\n    && git config --global color.diff.new \"green bold\" \\\n    && git config --global color.diff.whitespace \"red reverse\" \\\n    && git config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset - %s %Cgreen(%cr) %C(bold blue)<%an>%Creset%C(auto)%d%Creset' --abbrev-commit --\" \\\n    && git config --global http.sslVerify false \\\n    && git config --global pull.rebase true\n\n# Configure zsh\nCOPY --chown=root:root <<-\"EOF\" /root/.zshrc\nexport ZSH=\"/root/.oh-my-zsh\"\n\n# Theme\nZSH_THEME=\"robbyrussell\"\n\n# Plugins\nplugins=(\n    git\n    z\n    zsh-autosuggestions\n    zsh-syntax-highlighting\n)\n\nsource $ZSH/oh-my-zsh.sh\n\n# Aliases\nalias ll='ls -alF'\nalias la='ls -A'\nalias l='ls -CF'\nalias vi='vim'\n\n# Enhanced history\nHISTSIZE=10000\nSAVEHIST=10000\nsetopt HIST_IGNORE_ALL_DUPS\nsetopt HIST_FIND_NO_DUPS\nsetopt INC_APPEND_HISTORY\nEOF\n\nRUN set -euxo ; \\\n    curl --proto '=https' --tlsv1.2 -sSf https://just.systems/install.sh | bash -s -- --to /usr/local/bin\n\n# Set workspace directory\nWORKDIR /sgl-workspace/sglang\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.6.1\nFROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04\n\nARG BUILD_TYPE=all\nARG DEEPEP_COMMIT=b6ce310bb0b75079682d09bc2ebc063a074fbd58\nARG CMAKE_BUILD_PARALLEL_LEVEL=2\nENV DEBIAN_FRONTEND=noninteractive \\\n    CUDA_HOME=/usr/local/cuda \\\n    GDRCOPY_HOME=/usr/src/gdrdrv-2.4.4/ \\\n    NVSHMEM_DIR=/sgl-workspace/nvshmem/install\n\n# Set timezone and install all packages\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n && apt-get update && apt-get install -y --no-install-recommends \\\n    tzdata \\\n    software-properties-common netcat-openbsd kmod unzip openssh-server \\\n    curl wget lsof zsh ccache tmux htop git-lfs tree \\\n    python3 python3-pip python3-dev libpython3-dev python3-venv \\\n    build-essential cmake \\\n    libopenmpi-dev libnuma1 libnuma-dev \\\n    libibverbs-dev libibverbs1 libibumad3 \\\n    librdmacm1 libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnl-3-dev \\\n    ibverbs-providers infiniband-diags perftest \\\n    libgoogle-glog-dev libgtest-dev libjsoncpp-dev libunwind-dev \\\n    libboost-all-dev libssl-dev \\\n    libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc \\\n    pybind11-dev \\\n    libhiredis-dev libcurl4-openssl-dev \\\n    libczmq4 libczmq-dev \\\n    libfabric-dev \\\n    patchelf \\\n    nvidia-dkms-550 \\\n    devscripts debhelper fakeroot dkms check libsubunit0 libsubunit-dev \\\n && ln -sf /usr/bin/python3 /usr/bin/python \\\n && rm -rf /var/lib/apt/lists/* \\\n && apt-get clean\n\n# GDRCopy installation\nRUN mkdir -p /tmp/gdrcopy && cd /tmp \\\n && git clone https://github.com/NVIDIA/gdrcopy.git -b v2.4.4 \\\n && cd gdrcopy/packages \\\n && CUDA=/usr/local/cuda ./build-deb-packages.sh \\\n && dpkg -i gdrdrv-dkms_*.deb libgdrapi_*.deb gdrcopy-tests_*.deb gdrcopy_*.deb \\\n && cd / && rm -rf /tmp/gdrcopy\n\n# Fix DeepEP IBGDA symlink\nRUN ln -sf /usr/lib/x86_64-linux-gnu/libmlx5.so.1 /usr/lib/x86_64-linux-gnu/libmlx5.so\n\n# Clone and install SGLang\nWORKDIR /sgl-workspace\nRUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel html5lib six \\\n && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n && cd sglang \\\n && case \"$CUDA_VERSION\" in \\\n      12.6.1) CUINDEX=126 ;; \\\n      12.8.1) CUINDEX=128 ;; \\\n      *) echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1 ;; \\\n    esac \\\n && python3 -m pip install --no-cache-dir -e \"python[${BUILD_TYPE}]\" --extra-index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n      python3 -m pip install --no-cache-dir nvidia-nccl-cu12==2.27.6 --force-reinstall --no-deps ; \\\n      python3 -m pip install --no-cache-dir https://github.com/sgl-project/whl/releases/download/v0.2.7/sgl_kernel-0.2.7+cu128-cp39-abi3-manylinux2014_x86_64.whl --force-reinstall --no-deps ; \\\n    fi\n\n# Build and install NVSHMEM + DeepEP\nRUN wget https://developer.download.nvidia.com/compute/redist/nvshmem/3.3.9/source/nvshmem_src_cuda12-all-all-3.3.9.tar.gz \\\n && git clone https://github.com/deepseek-ai/DeepEP.git \\\n && cd DeepEP && git checkout ${DEEPEP_COMMIT} && cd .. \\\n && tar -xf nvshmem_src_cuda12-all-all-3.3.9.tar.gz && mv nvshmem_src nvshmem \\\n && cd nvshmem \\\n && rm -f /sgl-workspace/nvshmem_src_cuda12-all-all-3.3.9.tar.gz \\\n && NVSHMEM_SHMEM_SUPPORT=0 \\\n    NVSHMEM_UCX_SUPPORT=0 \\\n    NVSHMEM_USE_NCCL=0 \\\n    NVSHMEM_MPI_SUPPORT=0 \\\n    NVSHMEM_IBGDA_SUPPORT=1 \\\n    NVSHMEM_PMIX_SUPPORT=0 \\\n    NVSHMEM_TIMEOUT_DEVICE_POLLING=0 \\\n    NVSHMEM_USE_GDRCOPY=1 \\\n    cmake -S . -B build/ -DCMAKE_INSTALL_PREFIX=${NVSHMEM_DIR} -DCMAKE_CUDA_ARCHITECTURES=90 \\\n && cmake --build build --target install -j${CMAKE_BUILD_PARALLEL_LEVEL} \\\n && cd /sgl-workspace/DeepEP \\\n && NVSHMEM_DIR=${NVSHMEM_DIR} pip install .\n\n# Python tools\nRUN python3 -m pip install --no-cache-dir \\\n    datamodel_code_generator \\\n    mooncake_transfer_engine==0.3.4.post2 \\\n    pre-commit \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    uv \\\n    wheel \\\n    scikit-build-core\n\n# Install development tools and utilities\nRUN apt-get update && apt-get install -y \\\n    gdb \\\n    ninja-build \\\n    vim \\\n    tmux \\\n    htop \\\n    wget \\\n    curl \\\n    locales \\\n    lsof \\\n    git \\\n    git-lfs \\\n    zsh \\\n    tree \\\n    silversearcher-ag \\\n    cloc \\\n    unzip \\\n    pkg-config \\\n    libssl-dev \\\n    bear \\\n    ccache \\\n    less \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt-get clean\n\nRUN apt update -y \\\n    && apt install -y --no-install-recommends gnupg \\\n    && echo \"deb http://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64 /\" | tee /etc/apt/sources.list.d/nvidia-devtools.list \\\n    && apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub \\\n    && apt update -y \\\n    && apt install nsight-systems-cli -y\n\n# Set up locale\nRUN locale-gen en_US.UTF-8\nENV LANG en_US.UTF-8\nENV LANGUAGE en_US:en\nENV LC_ALL en_US.UTF-8\n\n# Install minimal Python packages\nRUN python3 -m pip install --no-cache-dir --break-system-packages \\\n    pytest \\\n    black \\\n    isort \\\n    icdiff \\\n    scikit_build_core \\\n    uv \\\n    pre-commit \\\n    pandas \\\n    matplotlib \\\n    tabulate\n\n# Install diff-so-fancy\nRUN curl -LSso /usr/local/bin/diff-so-fancy https://github.com/so-fancy/diff-so-fancy/releases/download/v1.4.4/diff-so-fancy \\\n    && chmod +x /usr/local/bin/diff-so-fancy\n\n# Install clang-format\nRUN curl -LSso /usr/local/bin/clang-format https://github.com/muttleyxd/clang-tools-static-binaries/releases/download/master-32d3ac78/clang-format-16_linux-amd64 \\\n    && chmod +x /usr/local/bin/clang-format\n\n# Install clangd\nRUN curl -L https://github.com/clangd/clangd/releases/download/18.1.3/clangd-linux-18.1.3.zip -o clangd.zip \\\n    && unzip clangd.zip \\\n    && cp -r clangd_18.1.3/bin/* /usr/local/bin/ \\\n    && cp -r clangd_18.1.3/lib/* /usr/local/lib/ \\\n    && rm -rf clangd_18.1.3 clangd.zip\n\n# Install CMake\nRUN wget https://github.com/Kitware/CMake/releases/download/v3.31.1/cmake-3.31.1-linux-x86_64.tar.gz \\\n    && tar -xzf cmake-3.31.1-linux-x86_64.tar.gz \\\n    && cp -r cmake-3.31.1-linux-x86_64/bin/* /usr/local/bin/ \\\n    && cp -r cmake-3.31.1-linux-x86_64/share/* /usr/local/share/ \\\n    && rm -rf cmake-3.31.1-linux-x86_64 cmake-3.31.1-linux-x86_64.tar.gz\n\n# Add yank script\nCOPY --chown=root:root <<-\"EOF\" /usr/local/bin/yank\n#!/bin/bash\nput() {\n  esc=$1\n  test -n \"$TMUX\" -o -z \"${TERM##screen*}\" && esc=\"\\033Ptmux;\\033$esc\\033\\\\\"\n  printf \"$esc\"\n}\nput \"\\033]52;c;!\\a\"\nbuf=$( cat \"$@\" )\nlen=$( printf %s \"$buf\" | wc -c ) max=74994\ntest $len -gt $max && echo \"$0: input is $(( len - max )) bytes too long\" >&2\nput \"\\033]52;c;$( printf %s \"$buf\" | head -c $max | base64 | tr -d '\\r\\n' )\\a\"\ntest -n \"$TMUX\" && tmux set-buffer \"$buf\" ||:\nEOF\n\nRUN chmod +x /usr/local/bin/yank\n\n# Install oh-my-zsh and plugins\nRUN sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" \"\" --unattended \\\n    && git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions \\\n    && git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\n# Configure Vim\nCOPY --chown=root:root <<-\"EOF\" /root/.vimrc\nfunction! Yank(text) abort\n  let escape = system('yank', a:text)\n  if v:shell_error\n    echoerr escape\n  else\n    call writefile([escape], '/dev/tty', 'b')\n  endif\nendfunction\n\nnoremap <silent> <Leader>y y:<C-U>call Yank(@0)<CR>\n\n\" automatically run yank(1) whenever yanking in Vim\nfunction! CopyYank() abort\n  call Yank(join(v:event.regcontents, \"\\n\"))\nendfunction\n\nautocmd TextYankPost * call CopyYank()\n\n\" Basic settings\nset number\nsyntax on\nset mouse=a\nfiletype indent on\n\n\" Indentation\nset autoindent nosmartindent\nset smarttab\nset expandtab\nset shiftwidth=4\nset softtabstop=4\n\n\" Visual guides\nset colorcolumn=120\nhighlight ColorColumn ctermbg=5\n\n\" Status line\nset laststatus=2\nset statusline=%<%f\\ %h%m%r%=%{\\\"[\\\".(&fenc==\\\"\\\"?&enc:&fenc).((exists(\\\"+bomb\\\")\\ &&\\ &bomb)?\\\",B\\\":\\\"\\\").\\\"]\\ \\\"}%k\\ %-14.(%l,%c%V%)\\ %P\n\n\" Backspace behavior\nset backspace=2\n\n\" Encoding\nset encoding=utf-8\nset fileencoding=utf-8\nEOF\n\n# Configure tmux\nCOPY --chown=root:root <<-\"EOF\" /root/.tmux.conf\n# Pane border styling\nset -g pane-border-style fg='#742727',bg=black\nset -g pane-active-border-style fg=red,bg=black\n\n# Status bar styling\nset -g status-style bg='#0C8A92',fg=black\n\n# Change prefix key to backtick\nset-option -g prefix `\nunbind C-b\nbind-key ` send-prefix\n\n# Split panes using - and = with current path\nunbind '\"'\nbind - splitw -v -c '#{pane_current_path}'\nunbind '%'\nbind = splitw -h -c '#{pane_current_path}'\n\n# Vi mode settings\nbind-key -T copy-mode-vi Y send-keys -X copy-pipe 'yank > #{pane_tty}'\nset-window-option -g mode-keys vi\n\n# Other settings\nset-option -g escape-time 0\nset-option -g base-index 1\nset-window-option -g mouse on\nEOF\n\n# Configure Git\nRUN git config --global core.editor \"vim\" \\\n    && git config --global core.whitespace \"fix,-indent-with-non-tab,trailing-space,cr-at-eol\" \\\n    && git config --global core.pager \"diff-so-fancy | less --tabs=4 -RFX\" \\\n    && git config --global color.ui true \\\n    && git config --global color.\"diff-highlight\".oldNormal \"red bold\" \\\n    && git config --global color.\"diff-highlight\".oldHighlight \"red bold 52\" \\\n    && git config --global color.\"diff-highlight\".newNormal \"green bold\" \\\n    && git config --global color.\"diff-highlight\".newHighlight \"green bold 22\" \\\n    && git config --global color.diff.meta \"11\" \\\n    && git config --global color.diff.frag \"magenta bold\" \\\n    && git config --global color.diff.commit \"yellow bold\" \\\n    && git config --global color.diff.old \"red bold\" \\\n    && git config --global color.diff.new \"green bold\" \\\n    && git config --global color.diff.whitespace \"red reverse\" \\\n    && git config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset - %s %Cgreen(%cr) %C(bold blue)<%an>%Creset%C(auto)%d%Creset' --abbrev-commit --\" \\\n    && git config --global http.sslVerify false \\\n    && git config --global pull.rebase true\n\n# Configure zsh\nCOPY --chown=root:root <<-\"EOF\" /root/.zshrc\nexport ZSH=\"/root/.oh-my-zsh\"\n\n# Theme\nZSH_THEME=\"robbyrussell\"\n\n# Plugins\nplugins=(\n    git\n    z\n    zsh-autosuggestions\n    zsh-syntax-highlighting\n)\n\nsource $ZSH/oh-my-zsh.sh\n\n# Aliases\nalias ll='ls -alF'\nalias la='ls -A'\nalias l='ls -CF'\nalias vi='vim'\n\n# Enhanced history\nHISTSIZE=10000\nSAVEHIST=10000\nsetopt HIST_IGNORE_ALL_DUPS\nsetopt HIST_FIND_NO_DUPS\nsetopt INC_APPEND_HISTORY\nEOF\n\nRUN set -euxo ; \\\n    curl --proto '=https' --tlsv1.2 -sSf https://just.systems/install.sh | bash -s -- --to /usr/local/bin\n\n# Set workspace directory\nWORKDIR /sgl-workspace/sglang\n"}
{"commit_hash": "ab4a83b25909aa98330b838a224e4fe5c943e483", "commit_short": "ab4a83b25909", "commit_subject": "Optimize schedule (#1339)", "pr_url": "https://github.com/sgl-project/sglang/pull/1339", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Docker: flashinfer/torch ABI mismatch - rebuild image with matching versions", "error_date": "2026-01-04", "parent_commit": "62f15eea5a0b4266cdae965d0337fd33f6673736", "human_only_success": true, "human_only_date": "2026-01-06", "human_throughput": 1428.5, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "ac971ff633de330de3ded7f7475caaf7cd5bbdcd", "commit_short": "ac971ff633de", "commit_subject": "perf: reduce ttft and itl with stream_interval 1 (#658)", "pr_url": "https://github.com/sgl-project/sglang/pull/658", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Server failed to start - outlines version incompatibility", "error_date": "2026-01-06", "parent_commit": "e1792cca2491af86f29782a3b83533a6566ac75b", "human_only_success": false, "human_only_date": "2026-01-06", "dockerfile_fixes": {"outlines": ">=0.0.44,<0.1.0", "note": "Old sglang v0.1.21 uses outlines.fsm.guide API removed in outlines 0.1.0+"}, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu22.04\n\nARG CUDA_VERSION=12.4.1\nARG PYTHON_VERSION=3\n\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt-get update -y \\\n    && apt-get install -y ccache software-properties-common \\\n    && add-apt-repository ppa:deadsnakes/ppa \\\n    && apt-get update -y \\\n    && apt-get install -y python${PYTHON_VERSION} python${PYTHON_VERSION}-dev python${PYTHON_VERSION}-venv python3-pip \\\n    && if [ \"${PYTHON_VERSION}\" != \"3\" ]; then update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 1; fi \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt-get clean\n\nRUN apt-get update -y \\\n    && apt-get install -y python3-pip git curl sudo\n\n# Workaround for https://github.com/openai/triton/issues/2507 and\n# https://github.com/pytorch/pytorch/issues/107960 -- hopefully\n# this won't be needed for future versions of this docker image\n# or future versions of triton.\nRUN ldconfig /usr/local/cuda-$(echo $CUDA_VERSION | cut -d. -f1,2)/compat/\n\nWORKDIR /sgl-workspace\n\nRUN pip3 --no-cache-dir install --upgrade pip \\\n    && pip3 --no-cache-dir install \"sglang[all]\" \\\n    && pip3 --no-cache-dir uninstall -y triton triton-nightly \\\n    && pip3 --no-cache-dir install --no-deps --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/ triton-nightly \\\n    && pip3 --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.3/\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu22.04\n\nARG CUDA_VERSION=12.4.1\nARG PYTHON_VERSION=3\n\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt-get update -y \\\n    && apt-get install -y ccache software-properties-common \\\n    && add-apt-repository ppa:deadsnakes/ppa \\\n    && apt-get update -y \\\n    && apt-get install -y python${PYTHON_VERSION} python${PYTHON_VERSION}-dev python${PYTHON_VERSION}-venv python3-pip \\\n    && if [ \"${PYTHON_VERSION}\" != \"3\" ]; then update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 1; fi \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt-get clean\n\nRUN apt-get update -y \\\n    && apt-get install -y python3-pip git curl sudo\n\n# Workaround for https://github.com/openai/triton/issues/2507 and\n# https://github.com/pytorch/pytorch/issues/107960 -- hopefully\n# this won't be needed for future versions of this docker image\n# or future versions of triton.\nRUN ldconfig /usr/local/cuda-$(echo $CUDA_VERSION | cut -d. -f1,2)/compat/\n\nWORKDIR /sgl-workspace\n\nRUN pip3 --no-cache-dir install --upgrade pip \\\n    && pip3 --no-cache-dir install \"sglang[all]\" \\\n    && pip3 --no-cache-dir uninstall -y triton triton-nightly \\\n    && pip3 --no-cache-dir install --no-deps --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/ triton-nightly \\\n    && pip3 --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.3/\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "b170930534acbb9c1619a3c83670a839ceee763a", "commit_short": "b170930534ac", "commit_subject": "feat: radix tree code optimize (#1697)", "pr_url": "https://github.com/sgl-project/sglang/pull/1697", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Docker: flashinfer/torch ABI mismatch - rebuild image with matching versions", "error_date": "2026-01-04", "parent_commit": "5ab20cceba227479bf5088a3fc95b1b4fe0ac3a9", "human_only_success": true, "human_only_date": "2026-01-06", "human_throughput": 661.8, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "b1e5a33ae337d20e35e966b8d82a02a913d32689", "commit_short": "b1e5a33ae337", "commit_subject": "Eliminate stream sync to speed up LoRA batch init  (#6960)", "pr_url": "https://github.com/sgl-project/sglang/pull/6960", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "9d5fa68b903d295d2b39201d54905c6801f60f7f", "human_throughput": 1593.6, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "b77a02cdfdb4cd58be3ebc6a66d076832c309cfc", "commit_short": "b77a02cdfdb4", "commit_subject": "[Performance] Support both xgrammar and outlines for constrained decoding (#1752)", "pr_url": "https://github.com/sgl-project/sglang/pull/1752", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Server failed to start", "error_date": "2026-01-06", "parent_commit": "30643fed7f92be32540dfcdf9e4310e477ce0f6d", "human_only_success": false, "human_only_date": "2026-01-06", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "bb3a3b6675b1844a13ebe368ad693f3dc75b315b", "commit_short": "bb3a3b6675b1", "commit_subject": "Support Faster JSON decoding for llava (#137)", "pr_url": "https://github.com/sgl-project/sglang/pull/137", "models": ["llava-hf/llava-1.5-7b-hf", "llava-hf/llava-1.5-13b-hf"], "perf_command": "python -m sglang.bench_serving --model llava-hf/llava-1.5-7b-hf --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Server failed to start", "error_date": "2026-01-06", "parent_commit": "45d6592d4053fe8b2b8dc9440f64c900de040d09", "human_only_success": false, "human_only_date": "2026-01-06", "has_dockerfile": false, "dockerfile_path": null, "dockerfile_content": null, "parent_has_dockerfile": false, "parent_dockerfile_path": null, "parent_dockerfile_content": null}
{"commit_hash": "c98e84c21e4313d7d307425ca43e61753a53a9f7", "commit_short": "c98e84c21e43", "commit_subject": "[Minor, Performance] Use torch.argmax for greedy sampling (#1589)", "pr_url": "https://github.com/sgl-project/sglang/pull/1589", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Docker: flashinfer/torch ABI mismatch - rebuild image with matching versions", "error_date": "2026-01-04", "parent_commit": "9c064bf78af8558dbc50fbd809f65dcafd6fd965", "human_only_success": true, "human_only_date": "2026-01-06", "human_throughput": 624.8, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "d1112d8548eb13c842900b3a8d622345f9737759", "commit_short": "d1112d8548eb", "commit_subject": "Add endpoint for file support, purely to speed up processing of input_embeds. (#2797)", "pr_url": "https://github.com/sgl-project/sglang/pull/2797", "models": ["google/gemma-2-2b"], "perf_command": "python -m sglang.bench_serving --model google/gemma-2-2b --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "48efec7b052354865aa2f0605a5bf778721f3cbb", "human_throughput": 3127.8, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.5.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.5/flashinfer-python\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.5.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.5/flashinfer-python\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "da47621ccc4f8e8381f3249257489d5fe32aff1b", "commit_short": "da47621ccc4f", "commit_subject": "Minor speedup topk postprocessing (#7058)", "pr_url": "https://github.com/sgl-project/sglang/pull/7058", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Docker: Modal image build failed - rebuild Docker image", "error_date": "2026-01-04", "parent_commit": "22a6b9fc051154347b6eb5064d2f6ef9b4dba471", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.12-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator --break-system-packages\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six --break-system-packages --ignore-installed \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118 --break-system-packages; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && if [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu126 --break-system-packages; \\\n       else \\\n         python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} --break-system-packages; \\\n       fi \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --break-system-packages \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps --break-system-packages; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.12-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator --break-system-packages\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six --break-system-packages --ignore-installed \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118 --break-system-packages; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && if [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu126 --break-system-packages; \\\n       else \\\n         python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} --break-system-packages; \\\n       fi \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --break-system-packages \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps --break-system-packages; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "dc67d9769382cf83b3e2644a4366d6473445a6c6", "commit_short": "dc67d9769382", "commit_subject": "misc: speedup load safetensors (#1319)", "pr_url": "https://github.com/sgl-project/sglang/pull/1319", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python3 -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 5000", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Docker: flashinfer/torch ABI mismatch - rebuild image with matching versions", "error_date": "2026-01-04", "parent_commit": "1e495e08470b6dc56645081f644831e0c620dfa5", "human_only_success": true, "human_only_date": "2026-01-06", "human_throughput": 653.3, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "dd1012fcbe2a1fb36c44e10c16f8d0bcd8e9da25", "commit_short": "dd1012fcbe2a", "commit_subject": "[PD] Fix potential perf spike caused by tracker gc and optimize doc (#6764)", "pr_url": "https://github.com/sgl-project/sglang/pull/6764", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "44aab7f91c350b1c6ecb77a7a34efb98af106cb5", "human_throughput": 1553.6, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "ddcf9fe3beacd8aed573c711942194dd02350da4", "commit_short": "ddcf9fe3beac", "commit_subject": "Optimize triton attention custom mask (#3731)", "pr_url": "https://github.com/sgl-project/sglang/pull/3731", "models": ["meta-llama/Llama-2-7b-chat-hf"], "perf_command": "python3 -m sglang.bench_serving --backend sglang --model meta-llama/Llama-2-7b-chat-hf --speculative-algo EAGLE", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Model load failure (no metrics)", "error_date": "2026-01-06", "parent_commit": "6252ade98571c3374d7e7df3430a2bfbddfc5eb3", "human_only_success": false, "human_only_date": "2026-01-06", "skip": true, "skip_reason": "Requires EAGLE speculative decoding setup - can't run with generic bench_serving command", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.5.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu118; \\\n         python3 -m pip install sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu121/torch2.5/flashinfer-python; \\\n         elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu124/torch2.5/flashinfer-python; \\\n         elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu124/torch2.5/flashinfer-python; \\\n         elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu118/torch2.5/flashinfer-python; \\\n           python3 -m pip install sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n         else \\\n           echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n         fi; \\\n       else \\\n         if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu121/torch2.5/flashinfer-python; \\\n         elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu124/torch2.5/flashinfer-python; \\\n         elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu124/torch2.5/flashinfer-python; \\\n         elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu118/torch2.5/flashinfer-python; \\\n           python3 -m pip install sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n         else \\\n           echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n         fi; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.5.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         python3 -m pip install torch --index-url https://download.pytorch.org/whl/cu118; \\\n         python3 -m pip install sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu121/torch2.5/flashinfer-python; \\\n         elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu124/torch2.5/flashinfer-python; \\\n         elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu124/torch2.5/flashinfer-python; \\\n         elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[srt]\" --find-links https://flashinfer.ai/whl/cu118/torch2.5/flashinfer-python; \\\n           python3 -m pip install sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n         else \\\n           echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n         fi; \\\n       else \\\n         if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu121/torch2.5/flashinfer-python; \\\n         elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu124/torch2.5/flashinfer-python; \\\n         elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu124/torch2.5/flashinfer-python; \\\n         elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n           python3 -m pip --no-cache-dir install -e \"python[all]\" --find-links https://flashinfer.ai/whl/cu118/torch2.5/flashinfer-python; \\\n           python3 -m pip install sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n         else \\\n           echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n         fi; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "df7f61ee7d235936e6663f07813d7c03c4ec1603", "commit_short": "df7f61ee7d23", "commit_subject": "Speed up rebalancing when using non-static dispatch algorithms (#6812)", "pr_url": "https://github.com/sgl-project/sglang/pull/6812", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": true, "human_only_date": "2026-01-04", "baseline_only_success": true, "baseline_only_date": "2026-01-04", "agent_only_success": true, "agent_only_date": "2026-01-04", "parent_commit": "ef21729c1d8fdd9575cb2c8aaea96c94481c10fa", "human_throughput": 1547.6, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.6/flashinfer-python \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "e3ec6bf4b65a50e26e936a96adc7acc618292002", "commit_short": "e3ec6bf4b65a", "commit_subject": "Minor speed up block_quant_dequant (#6814)", "pr_url": "https://github.com/sgl-project/sglang/pull/6814", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Docker: Modal image build failed - rebuild Docker image", "error_date": "2026-01-04", "parent_commit": "b04df75acdda5b99999c02820e64b5b005c07159", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.12-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator --break-system-packages\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six --break-system-packages --ignore-installed \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118 --break-system-packages; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && if [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu126 --break-system-packages; \\\n       else \\\n         python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} --break-system-packages; \\\n       fi \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --break-system-packages \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps --break-system-packages; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.4.1\n\nFROM nvcr.io/nvidia/tritonserver:24.12-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && apt install python3 python3-pip -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install rdma-core infiniband-diags openssh-server perftest -y \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator --break-system-packages\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six --break-system-packages --ignore-installed \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118 --break-system-packages; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && if [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu126 --break-system-packages; \\\n       else \\\n         python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} --break-system-packages; \\\n       fi \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --break-system-packages \\\n    && if [ \"$CUDA_VERSION\" = \"12.8.1\" ]; then \\\n         python3 -m pip install nvidia-nccl-cu12==2.26.2.post1 --force-reinstall --no-deps --break-system-packages; \\\n       fi\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "e5db40dcbce67157e005f524bf6a5bea7dcb7f34", "commit_short": "e5db40dcbce6", "commit_subject": "ORJson. Faster Json serialization (#1694)", "pr_url": "https://github.com/sgl-project/sglang/pull/1694", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct --num-prompts 100", "hardware": "H100", "has_serving": true, "repo": "sglang", "error": "Docker: flashinfer/torch ABI mismatch - rebuild image with matching versions", "error_date": "2026-01-04", "parent_commit": "b170930534acbb9c1619a3c83670a839ceee763a", "human_only_success": true, "human_only_date": "2026-01-06", "human_throughput": 652.8, "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.1.1\nFROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && cd sglang \\\n    && if [ \"$BUILD_TYPE\" = \"srt\" ]; then \\\n         python3 -m pip --no-cache-dir install -e \"python[srt]\"; \\\n       else \\\n         python3 -m pip --no-cache-dir install -e \"python[all]\"; \\\n       fi\n\nARG CUDA_VERSION\nRUN if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu121 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n        export CUDA_IDENTIFIER=cu124 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/; \\\n    elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n        export CUDA_IDENTIFIER=cu118 && \\\n        python3 -m pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118 && \\\n        python3 -m pip --no-cache-dir install flashinfer -i https://flashinfer.ai/whl/cu118/torch2.4/; \\\n    else \\\n        echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n    fi\n\nRUN python3 -m pip cache purge\n\n\nENV DEBIAN_FRONTEND=interactive\n"}
{"commit_hash": "e822e5900b98d89d19e0a293d9ad384f4df2945a", "commit_short": "e822e5900b98", "commit_subject": "Optimize radix tree matching (#364)", "pr_url": "https://github.com/sgl-project/sglang/pull/364", "models": ["meta-llama/Llama-2-13b-chat-hf"], "perf_command": "python -m sglang.bench_serving --backend sglang --model meta-llama/Llama-2-13b-chat-hf --num-prompts 1000 --request-rate 128", "hardware": "H100", "has_serving": true, "repo": "sglang", "human_only_success": false, "human_only_date": "2026-01-04", "error": "Benchmark script path error - empty metrics", "error_date": "2026-01-04", "parent_commit": "ca4f1ab89c0c9bdd80fdfabcec52968fbde108bb", "has_dockerfile": false, "dockerfile_path": null, "dockerfile_content": null, "parent_has_dockerfile": false, "parent_dockerfile_path": null, "parent_dockerfile_content": null}
{"commit_hash": "93470a14116a60fe5dd43f0599206e8ccabdc211", "commit_short": "93470a14116a", "commit_subject": "Refactor and Optimize FA3 Code (#5090)", "pr_url": "https://github.com/sgl-project/sglang/pull/5090", "models": ["meta-llama/Llama-3.1-8B-Instruct"], "perf_command": "python3 -m sglang.bench_serving --backend sglang --model meta-llama/Llama-3.1-8B-Instruct", "hardware": "H200", "has_serving": true, "repo": "sglang", "parent_commit": "db452760e5b2378efd06b1ceb9385d2eeb6d217c", "has_dockerfile": true, "dockerfile_path": "docker/Dockerfile", "dockerfile_content": "ARG CUDA_VERSION=12.5.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.5/flashinfer-python\n\nENV DEBIAN_FRONTEND=interactive\n", "parent_has_dockerfile": true, "parent_dockerfile_path": "docker/Dockerfile", "parent_dockerfile_content": "ARG CUDA_VERSION=12.5.1\n\nFROM nvcr.io/nvidia/tritonserver:24.04-py3-min\n\nARG BUILD_TYPE=all\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \\\n    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \\\n    && apt update -y \\\n    && apt install software-properties-common -y \\\n    && add-apt-repository ppa:deadsnakes/ppa -y && apt update \\\n    && apt install python3.10 python3.10-dev -y \\\n    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 \\\n    && update-alternatives --set python3 /usr/bin/python3.10 && apt install python3.10-distutils -y \\\n    && apt install curl git sudo libibverbs-dev -y \\\n    && apt install -y rdma-core infiniband-diags openssh-server perftest ibverbs-providers libibumad3 libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 \\\n    && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py \\\n    && python3 --version \\\n    && python3 -m pip --version \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt clean\n\n# For openbmb/MiniCPM models\nRUN pip3 install datamodel_code_generator\n\nWORKDIR /sgl-workspace\n\nARG CUDA_VERSION\nRUN python3 -m pip install --upgrade pip setuptools wheel html5lib six \\\n    && git clone --depth=1 https://github.com/sgl-project/sglang.git \\\n    && if [ \"$CUDA_VERSION\" = \"12.1.1\" ]; then \\\n         export CUINDEX=121; \\\n       elif [ \"$CUDA_VERSION\" = \"12.4.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"12.5.1\" ]; then \\\n         export CUINDEX=124; \\\n       elif [ \"$CUDA_VERSION\" = \"11.8.0\" ]; then \\\n         export CUINDEX=118; \\\n         python3 -m pip install --no-cache-dir sgl-kernel -i https://docs.sglang.ai/whl/cu118; \\\n       else \\\n         echo \"Unsupported CUDA version: $CUDA_VERSION\" && exit 1; \\\n       fi \\\n    && python3 -m pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu${CUINDEX} \\\n    && cd sglang \\\n    && python3 -m pip --no-cache-dir install -e \"python[${BUILD_TYPE}]\" --find-links https://flashinfer.ai/whl/cu${CUINDEX}/torch2.5/flashinfer-python\n\nENV DEBIAN_FRONTEND=interactive\n"}